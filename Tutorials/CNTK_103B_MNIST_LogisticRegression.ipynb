{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "nbpresent": {
     "id": "29b9bd1d-766f-4422-ad96-de0accc1ce58"
    }
   },
   "source": [
    "# CNTK 103: Part B - Logistic Regression with MNIST\n",
    "\n",
    "We assume that you have successfully completed CNTK 103 Part A.\n",
    "\n",
    "In this tutorial we will build and train a Multiclass Logistic Regression model using the MNIST data. This notebook provides the recipe using Python APIs. If you are looking for this example in BrainScript, please look [here](https://github.com/Microsoft/CNTK/tree/v2.0.rc2/Examples/Image/GettingStarted)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**Problem**:\n",
    "Optical Character Recognition (OCR) is a hot area research and there is a great demand for automation. The MNIST data comprises of hand-written digits with little background noise making it a nice dataset to create, experiment and learn deep learning models with reasonably small comptuing resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://3.bp.blogspot.com/_UpN7DfJA0j4/TJtUBWPk0SI/AAAAAAAAABY/oWPMtmqJn3k/s1600/mnist_originals.png\" width=\"200\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Figure 1\n",
    "Image(url= \"http://3.bp.blogspot.com/_UpN7DfJA0j4/TJtUBWPk0SI/AAAAAAAAABY/oWPMtmqJn3k/s1600/mnist_originals.png\", width=200, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Goal**:\n",
    "Our goal is to train a classifier that will identify the digits in the MNIST dataset. \n",
    "\n",
    "**Approach**:\n",
    "The same 5 stages we have used in the previous tutorial are applicable: Data reading, Data preprocessing, Creating a model, Learning the model parameters and Evaluating (a.k.a. testing/prediction) the model. \n",
    "- Data reading: We will use the CNTK Text reader \n",
    "- Data preprocessing: Covered in part A (suggested extension section). \n",
    "\n",
    "Rest of the steps are kept identical to CNTK 102. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Logistic Regression\n",
    "[Logistic Regression](https://en.wikipedia.org/wiki/Logistic_regression) (LR) is a fundamental machine learning technique that uses a linear weighted combination of features and generates probability-based predictions of different classes.  \n",
    "â€‹\n",
    "There are two basic forms of LR: **Binary LR** (with a single output that can predict two classes) and **multinomial LR** (with multiple outputs, each of which is used to predict a single class).  \n",
    "\n",
    "![LR-forms](http://www.cntk.ai/jup/cntk103b_TwoFormsOfLR-v3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In **Binary Logistic Regression** (see top of figure above), the input features are each scaled by an associated weight and summed together.  The sum is passed through a squashing (aka activation) function and generates an output in [0,1].  This output value (which can be thought of as a probability) is then compared with a threshold (such as 0.5) to produce a binary label (0 or 1).  This technique supports only classification problems with two output classes, hence the name binary LR.  In the binary LR example shown above, the [sigmoid][] function is used as the squashing function.\n",
    "\n",
    "[sigmoid]: https://en.wikipedia.org/wiki/Sigmoid_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In **Multiclass Linear Regression** (see bottom of figure above), 2 or more output nodes are used, one for each output class to be predicted.  Each summation node uses its own set of weights to scale the input features and sum them together. Instead of passing the summed output of the weighted input features through a sigmoid squashing function, the output is often passed through a [softmax][] function (which in addition to squashing, like the sigmoid, the softmax normalizes each nodes' output value using the sum of all unnormalized nodes). (Details in the context of MNIST image to follow)\n",
    "\n",
    "In this tutorials, we will use multinomial LR for classifying the MNIST digits (0-9) using 10 output nodes (1 for each of our output classes).\n",
    "\n",
    "[softmax]: https://en.wikipedia.org/wiki/Softmax_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "nbpresent": {
     "id": "138d1a78-02e2-4bd6-a20e-07b83f303563"
    }
   },
   "outputs": [],
   "source": [
    "# Import the relevant components\n",
    "from __future__ import print_function # Use a function definition from future version (say 3.x from 2.7 interpreter)\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import cntk as C\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In the block below, we check if we are running this notebook in the CNTK internal test machines by looking for environment variables defined there. We then select the right target device (GPU vs CPU) to test this notebook. In other cases, we use CNTK's default policy to use the best available device (GPU, if available, else CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Select the right target device when this notebook is being tested:\n",
    "if 'TEST_DEVICE' in os.environ:\n",
    "    if os.environ['TEST_DEVICE'] == 'cpu':\n",
    "        C.device.try_set_default_device(C.device.cpu())\n",
    "    else:\n",
    "        C.device.try_set_default_device(C.device.gpu(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Ensure we always get the same amount of randomness\n",
    "np.random.seed(0)\n",
    "\n",
    "# Define the data dimensions\n",
    "input_dim = 784\n",
    "num_output_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data reading\n",
    "\n",
    "In this tutorial we are using the MNIST data you have downloaded using CNTK_103A_MNIST_DataLoader notebook. The dataset has 60,000 training images and 10,000 test images with each image being 28 x 28 pixels. Thus the number of features is equal to 784 (= 28 x 28 pixels), 1 per pixel. The variable `num_output_classes` is set to 10 corresponding to the number of digits (0-9) in the dataset.\n",
    "\n",
    "The data is in the following format:\n",
    "\n",
    "    |labels 0 0 0 1 0 0 0 0 0 0 |features 0 0 0 0 ... \n",
    "                                                  (784 integers each representing a pixel)\n",
    "    \n",
    "In this tutorial we are going to use the image pixels corresponding the integer stream named \"features\". We define a `create_reader` function to read the training and test data using the [CTF deserializer](https://cntk.ai/pythondocs/cntk.io.html?highlight=ctfdeserializer#cntk.io.CTFDeserializer). The labels are [1-hot encoded](https://en.wikipedia.org/wiki/One-hot). Refer to CNTK 103A tutorial for data format visualizations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read a CTF formatted text (as mentioned above) using the CTF deserializer from a file\n",
    "def create_reader(path, is_training, input_dim, num_label_classes):\n",
    "    \n",
    "    labelStream = C.io.StreamDef(field='labels', shape=num_label_classes, is_sparse=False)\n",
    "    featureStream = C.io.StreamDef(field='features', shape=input_dim, is_sparse=False)\n",
    "    \n",
    "    deserailizer = C.io.CTFDeserializer(path, C.io.StreamDefs(labels = labelStream, features = featureStream))\n",
    "            \n",
    "    return C.io.MinibatchSource(deserailizer,\n",
    "       randomize = is_training, max_sweeps = C.io.INFINITELY_REPEAT if is_training else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory is data\\MNIST\n"
     ]
    }
   ],
   "source": [
    "# Ensure the training and test data is generated and available for this tutorial.\n",
    "# We search in two locations in the toolkit for the cached MNIST data set.\n",
    "data_found = False\n",
    "\n",
    "for data_dir in [os.path.join(\"..\", \"Examples\", \"Image\", \"DataSets\", \"MNIST\"),\n",
    "                 os.path.join(\"data\", \"MNIST\")]:\n",
    "    train_file = os.path.join(data_dir, \"Train-28x28_cntk_text.txt\")\n",
    "    test_file = os.path.join(data_dir, \"Test-28x28_cntk_text.txt\")\n",
    "    if os.path.isfile(train_file) and os.path.isfile(test_file):\n",
    "        data_found = True\n",
    "        break\n",
    "        \n",
    "if not data_found:\n",
    "    raise ValueError(\"Please generate the data by completing CNTK 103 Part A\")\n",
    "    \n",
    "print(\"Data directory is {0}\".format(data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model Creation\n",
    "\n",
    "A logistic regression (LR) network is a simple building block that has been effectively powering many ML \n",
    "applications in the past decade. The figure below summarizes the model in the context of the MNIST data.\n",
    "\n",
    "![mnist-LR](https://www.cntk.ai/jup/cntk103b_MNIST_LR.png)\n",
    "\n",
    "LR is a simple linear model that takes as input, a vector of numbers describing the properties of what we are classifying (also known as a feature vector, $\\bf \\vec{x}$, the pixels in the input MNIST digit image) and emits the *evidence* ($z$). For each of the 10 digits, there is a vector of weights corresponding to the input pixels as show in the figure. These 10 weight vectors define the weight matrix ($\\bf {W}$) with dimension of 10 x 784.  Each feature in the input layer is connected with a summation node by a corresponding weight $w$ (individual weight values from the $\\bf{W}$ matrix). Note there are 10 such nodes, 1 corresponding to each digit to be classified. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The first step is to compute the evidence for an observation. \n",
    "\n",
    "$$\\vec{z} = \\textbf{W} \\bf \\vec{x}^T + \\vec{b}$$ \n",
    "\n",
    "where $\\bf{W}$ is the weight matrix of dimension 10 x 784 and $\\vec{b}$ is known as the *bias* vector with lenght 10, one for each digit. \n",
    "\n",
    "The evidence ($\\vec{z}$) is not squashed (hence no activation). Instead the output is normalized using a [softmax](https://en.wikipedia.org/wiki/Softmax_function) function such that all the outputs add up to a value of 1, thus lending a probabilistic iterpretation to the prediction. In CNTK, we use the softmax operation that is combined with the cross entropy error function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Network input and output: \n",
    "- **input** variable (a key CNTK concept): \n",
    ">An **input** variable is a container in which we fill different observations in this case image pixels during model learning (a.k.a.training) and model evaluation (a.k.a. testing). Thus, the shape of the `input` must match the shape of the data that will be provided.  For example, when data are images each of  height 10 pixels  and width 5 pixels, the input feature dimension will be 50 (representing the total number of image pixels). More on data and their dimensions to appear in separate tutorials.\n",
    "\n",
    "\n",
    "**Question** What is the input dimension of your chosen model? This is fundamental to our understanding of variables in a network or model representation in CNTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input = C.input(input_dim)\n",
    "label = C.input(num_output_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Logistic Regression network setup\n",
    "\n",
    "The CNTK Layers module provides a Dense function that creates a fully connected layer which performs the above operations of weighted input summing and bias addition.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_model(features):\n",
    "    with C.layers.default_options(init = C.glorot_uniform()):\n",
    "        r = C.layers.Dense(num_output_classes, activation = None)(features)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "`z` will be used to represent the output of a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Scale the input to 0-1 range by dividing each pixel by 255.\n",
    "z = create_model(input/255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Learning model parameters\n",
    "\n",
    "Same as the previous tutorial, we use the `softmax` function to map the accumulated evidences or activations to a probability distribution over the classes (Details of the [softmax function][] and other [activation][] functions).\n",
    "\n",
    "[softmax function]: http://cntk.ai/pythondocs/cntk.ops.html#cntk.ops.softmax\n",
    "\n",
    "[activation]: https://github.com/Microsoft/CNTK/wiki/Activation-Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training\n",
    "\n",
    "Similar to CNTK 102, we use minimize the cross-entropy between the label and predicted probability by the network. If this terminology sounds strange to you, please refer to the CNTK 102 for a refresher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loss = C.cross_entropy_with_softmax(z, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Evaluation\n",
    "\n",
    "In order to evaluate the classification, one can compare the output of the network which for each observation emits a vector of evidences (can be converted into probabilities using `softmax` functions) with dimension equal to number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "label_error = C.classification_error(z, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Configure training\n",
    "\n",
    "The trainer strives to reduce the `loss` function by different optimization approaches, [Stochastic Gradient Descent][] (`sgd`) being one of the most popular one. Typically, one would start with random initialization of the model parameters. The `sgd` optimizer would calculate the `loss` or error between the predicted label against the corresponding ground-truth label and using [gradient-decent][] generate a new set model parameters in a single iteration. \n",
    "\n",
    "The aforementioned model parameter update using a single observation at a time is attractive since it does not require the entire data set (all observation) to be loaded in memory and also requires gradient computation over fewer datapoints, thus allowing for training on large data sets. However, the updates generated using a single observation sample at a time can vary wildly between iterations. An intermediate ground is to load a small set of observations and use an average of the `loss` or error from that set to update the model parameters. This subset is called a *minibatch*.\n",
    "\n",
    "With minibatches, we often sample observation from the larger training dataset. We repeat the process of model parameters update using different combination of training samples and over a period of time minimize the `loss` (and the error). When the incremental error rates are no longer changing significantly or after a preset number of maximum minibatches to train, we claim that our model is trained.\n",
    "\n",
    "One of the key optimization parameter is called the `learning_rate`. For now, we can think of it as a scaling factor that modulates how much we change the parameters in any iteration. We will be covering more details in later tutorial. \n",
    "With this information, we are ready to create our trainer. \n",
    "\n",
    "[optimization]: https://en.wikipedia.org/wiki/Category:Convex_optimization\n",
    "[Stochastic Gradient Descent]: https://en.wikipedia.org/wiki/Stochastic_gradient_descent\n",
    "[gradient-decent]: http://www.statisticsviews.com/details/feature/5722691/Getting-to-the-Bottom-of-Regression-with-Gradient-Descent.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the trainer object to drive the model training\n",
    "learning_rate = 0.2\n",
    "lr_schedule = C.learning_rate_schedule(learning_rate, C.UnitType.minibatch)\n",
    "learner = C.sgd(z.parameters, lr_schedule)\n",
    "trainer = C.Trainer(z, (loss, label_error), [learner])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First let us create some helper functions that will be needed to visualize different functions associated with training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a utility function to compute the moving average sum.\n",
    "# A more efficient implementation is possible with np.cumsum() function\n",
    "def moving_average(a, w=5):\n",
    "    if len(a) < w:\n",
    "        return a[:]    # Need to send a copy of the array\n",
    "    return [val if idx < w else sum(a[(idx-w):idx])/w for idx, val in enumerate(a)]\n",
    "\n",
    "\n",
    "# Defines a utility that prints the training progress\n",
    "def print_training_progress(trainer, mb, frequency, verbose=1):\n",
    "    training_loss = \"NA\"\n",
    "    eval_error = \"NA\"\n",
    "\n",
    "    if mb%frequency == 0:\n",
    "        training_loss = trainer.previous_minibatch_loss_average\n",
    "        eval_error = trainer.previous_minibatch_evaluation_average\n",
    "        if verbose: \n",
    "            print (\"Minibatch: {0}, Loss: {1:.4f}, Error: {2:.2f}%\".format(mb, training_loss, eval_error*100))\n",
    "        \n",
    "    return mb, training_loss, eval_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id='#Run the trainer'></a>\n",
    "### Run the trainer\n",
    "\n",
    "We are now ready to train our fully connected neural net. We want to decide what data we need to feed into the training engine.\n",
    "\n",
    "In this example, each iteration of the optimizer will work on `minibatch_size` sized samples. We would like to train on all 60000 observations. Additionally we will make multiple passes through the data specified by the variable `num_sweeps_to_train_with`. With these parameters we can proceed with training our simple feed forward network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Initialize the parameters for the trainer\n",
    "minibatch_size = 64\n",
    "num_samples_per_sweep = 60000\n",
    "num_sweeps_to_train_with = 10\n",
    "num_minibatches_to_train = (num_samples_per_sweep * num_sweeps_to_train_with) / minibatch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch: 0, Loss: 0.1423, Error: 3.12%\n",
      "Minibatch: 500, Loss: 0.3628, Error: 12.50%\n",
      "Minibatch: 1000, Loss: 0.1876, Error: 1.56%\n",
      "Minibatch: 1500, Loss: 0.3623, Error: 12.50%\n",
      "Minibatch: 2000, Loss: 0.1427, Error: 4.69%\n",
      "Minibatch: 2500, Loss: 0.1646, Error: 6.25%\n",
      "Minibatch: 3000, Loss: 0.0887, Error: 1.56%\n",
      "Minibatch: 3500, Loss: 0.2794, Error: 9.38%\n",
      "Minibatch: 4000, Loss: 0.3449, Error: 7.81%\n",
      "Minibatch: 4500, Loss: 0.2448, Error: 4.69%\n",
      "Minibatch: 5000, Loss: 0.1615, Error: 3.12%\n",
      "Minibatch: 5500, Loss: 0.1144, Error: 3.12%\n",
      "Minibatch: 6000, Loss: 0.1309, Error: 3.12%\n",
      "Minibatch: 6500, Loss: 0.2656, Error: 7.81%\n",
      "Minibatch: 7000, Loss: 0.1518, Error: 6.25%\n",
      "Minibatch: 7500, Loss: 0.2889, Error: 7.81%\n",
      "Minibatch: 8000, Loss: 0.1050, Error: 3.12%\n",
      "Minibatch: 8500, Loss: 0.1447, Error: 6.25%\n",
      "Minibatch: 9000, Loss: 0.1036, Error: 3.12%\n"
     ]
    }
   ],
   "source": [
    "# Create the reader to training data set\n",
    "reader_train = create_reader(train_file, True, input_dim, num_output_classes)\n",
    "\n",
    "# Map the data streams to the input and labels.\n",
    "input_map = {\n",
    "    label  : reader_train.streams.labels,\n",
    "    input  : reader_train.streams.features\n",
    "} \n",
    "\n",
    "# Run the trainer on and perform model training\n",
    "training_progress_output_freq = 500\n",
    "\n",
    "plotdata = {\"batchsize\":[], \"loss\":[], \"error\":[]}\n",
    "\n",
    "for i in range(0, int(num_minibatches_to_train)):\n",
    "    \n",
    "    # Read a mini batch from the training data file\n",
    "    data = reader_train.next_minibatch(minibatch_size, input_map = input_map)\n",
    "    \n",
    "    trainer.train_minibatch(data)\n",
    "    batchsize, loss, error = print_training_progress(trainer, i, training_progress_output_freq, verbose=1)\n",
    "    \n",
    "    if not (loss == \"NA\" or error ==\"NA\"):\n",
    "        plotdata[\"batchsize\"].append(batchsize)\n",
    "        plotdata[\"loss\"].append(loss)\n",
    "        plotdata[\"error\"].append(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let us plot the errors over the different training minibatches. Note that as we iterate the training loss decreases though we do see some intermediate bumps. \n",
    "\n",
    "Hence, we use smaller minibatches and using `sgd` enables us to have a great scalability while being performant for large data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAACgCAYAAADjNXB5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOGW4UnAcx3HK+H/DO2rO7HcsmgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2501ffaf1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAACgCAYAAAAfIFuzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnXecFEX2wL9PgiQFBURBEFDAQz1AEcMpp4AZw6lnPhVM\nmNBT73dmz3TneebIGTAroocIHoiY8FRWBVlBCYoEAUEJIlEJ+35/vB63GWdme3bCzu687+fTn+mu\n6qp+Xdvbr6tevVeiqjiO4zhORWxW1QI4juM41QNXGI7jOE4kXGE4juM4kXCF4TiO40TCFYbjOI4T\nCVcYjuM4TiRcYVRTRGSQiFyX7rkicoCIzM+tdL9cd46I9MnHtaobIqIislO+y2ZK+NrpPIMJ6lkl\nIu2zK52Ta1xhFBjBS3adiDSLS58U/LO2BVDVAap6c5Q60zm3AtnaBjLUzrSumkAhtoeIvCsiPwUv\n5CUiMkxEtsvFtaI+V4FMZ8eVbaSqs7ItU/D/sza4/9j2QLavU6y4wihMZgMnxw5EZDegQdWJk38K\n6SVcDblIVRsBHYEmwN2JThKRWnmVKn8cGSik2HZRopMSPWPpPnfF9py6wihMngFODx2fATwdPkFE\nnhSRW4L9A0RkvohcLiLfi8hCEemX6NxQ2tXBF+gcETk1lH5E0JtZISLzRORvoWLvBb/Lgy+3fYIy\n54jINBFZKSJTRWT3UJmuIjJZRH4UkRdFpF6iGxaRM0XkAxG5W0SWAn8Tkb+JyLOhczb5og++XG8O\nyq0UkTfie2ahstNEpG/ouLaILBaR3UWknog8KyJLRWS5iHwiIi0S1RMVEekhIuOD+haKyAMiUjfu\ntMNFZFbwd/iXiGwWKt8/kPkHERkjIjukK4OqLgP+A+wa1PmkiDwsIqNEZDVwoIhsLiJ3iMg3IvJd\nMMxUPyTHXwL5vxWR/nH3uMlzJSJHi0hp8Ox8LSKHisitwP7AA+Gvfdl0aKuxiDwd/D3misi1sbYI\nnov3Axl/EJHZInJYum0Rqiv+GUuUtlkgw9zg/+lpEWkc1BF7Bs8SkW+AtysjS3XFFUZhUgJsKSK/\nEfsKPAl4toIy2wKNgVbAWcCDIrJVinObBeeeATwiIp2CvNWYsmoCHAGcLyLHBHk9g98mwZfbeBH5\nI/C3oMyWwFHA0tC1TgAOBdoBvwXOTHEPewGzgBbArRXcb4xTgH7ANkBd4Iok571AqNcGHAIsUdVP\nsTZoDLQGmgIDgLURr5+MjcCfsXbeB+gNXBB3zh+A7sDuwNFAf7AXL3A1cCzQHPhfIH9aBMrzOGBS\nKPkUrG23AN4HbsN6Il2BnbBn4vqg/KFYex4EdACS2qNEpAf2UfMX7NnpCcxR1WsC+S9K8bV/P9b+\n7YHfY89Sv1D+XsAMrC1vBx4XEYnaDnEkesbi084MtgMDmRoB8cNavwd+gz1HxYOq+lZAGzAH+8e8\nFvgH9rIdC9QGFGgbnPckcEuwfwD2gqsdqud7YO8k524AGobOHQpcl0See4C7g/22gQzh64wBLklx\nL6eFjm8HBiU590zgm7i0vwHPho43uT7wLnBtKP8C4PUk9e8ErAQaBMfPAdcH+/2BD4Hfpvm3+lV7\npDj3UuCV0LECh8bJ/lawPxo4K5S3GbAG2CFUdqck13k3OHc5sCC4z+ah5+Dp0LmCfSDsGErbB5gd\n7A8GbgvldQxfO+65+nfsOUki09lxaRr8TWoB64DOobzzgHdDz8XMUF6DoOy2KZ65VcH9x7ZzUjxj\nidLeAi4IHXcC1mP/g7G/efvK/o9X562oxt+qGc9gQ0DtiBuOSsJSVd0QOl6DfRkl4gdVXR06ngu0\nBBCRvbCvzl2xL/bNgZdSXLc18HWK/EVxMrVMce68FHlR6094z6o6U0SmAUeKyEisJ9QtyH4Gu48h\nItIE681do6rrKyEPACLSEbgL60E0wF42E+NOC9/vL38DYAfgXhG5M1wl9vU/N8LlB6rqY0nywtds\nHsg2MfTBLthLnECesMyprt0aGBVBtniaAXXi6p6L3WuMX/7GqromkDXZsw1wjKq+mSQv0TMWn9Yy\ngTy1sR5IqnpqPD4kVaCo6lzM+H04MCzL1W8lIg1Dx22Ab4P954ERQGtVbQwMwl4iYF9W8cwDdsyS\nXPH1r2ZTY/+2GdYfG5Y6GpiqqjMBVHW9qt6oqp2BfYG+bGpDqgwPA9OBDqq6JTbEFD+M0jq0H/4b\nzAPOU9Umoa2+qn6YoUywaRsvwXqmu4Su01jNYA6wMIGMyUj1HKQKib0E+3oP22jaYL2jXJBIlvi0\nbxPIswH4roJ6ajyuMAqbs4Becb2BbHGjiNQVkf2xF2SsF7EFsExVfwrGpU8JlVkMlGHjujEeA64Q\nkT3E2KkyBtoklAI9RaRNYHS8KsP6hgAHA+djihEAETlQRHYL7EUrsBdYWRr1bh4YzmPbZlg7rgBW\nicjOwTXj+YuIbCUirYFLgBeD9EHAVSKySyBf48BWlFVUtQx4FLhbRLYJrtVKRGLj8kOBM0Wks4g0\nAG5IUd3jQD8R6R0YjVsF9w32ok3oc6GqG4Pr3CoiWwTPzmVUbLPLJS8AfxaRdiLSCPg78GJcD74o\ncYVRwKjq16o6IQdVLwJ+wL6kngMGqOr0IO8C4CYRWYkZP4eG5FmDGQU/EJv9s7eqvhSkPY/ZCIYD\nW2dDSFUdi71EJ2NDI69lWN9CYDzWi3gxlLUt8DL2gp8GjMOGqWLOaYMqqHoV9qUe23phxuJTsDZ5\nNO56MV7F7qsU+C/20kVVXwH+iQ2RrQA+Byo1MygCfwVmAiXBtd7ExuxR1dGYDevt4JykM4JU9WPM\nUH038CPWhrEPh3uB44NZTvclKH4x1puchRnin8fsJ5VlpGzqh/FKmuUHUz4kPBv4KZCx6JHAqOM4\njuM4KfEehuM4jhMJVxiO4zhOJFIqDBGpJSLv5EsYx3Ecp3BJqTCCGQxlMbd4x3Ecp3iJ4ri3Cpgi\nImOxmQwAqOrAnEnlOI7jFBxRFMYwsu84lhOaNWumbdu2rWoxHMdxqg0TJ05coqrNo5xbocJQ1afE\nomx2DJJmZBIyIZe0bduWCRNy4bbgOI5TMxGRKOFmgAgKQ0QOAJ7CgnoJ0FpEzlDV91KVcxzHcWoW\nUYak7gQOVtUZ8EtQtReAPXIpmOM4jlNYRPHDqBNTFgCq+iUWXdIpNL74Au6+G5Ytq2pJHMepgURR\nGBNE5DGxVd0OEJFHATcUhJk6Fc47D554omrleOMNuOwyWF+QJibHcao5URTG+cBUYGCwTSVx5M3i\n5fnn4ZFH4Prrq1aOScHCaqNHV60cjuPUSFLaMIJwz4NV9VRsMRgnESUl9rtgAaxaBY1Sre2SQ0pL\n7bdfPzjkENhuu6qRw3GcGkkUT+8d5NeL1zsxNm6Ejz6C1q1BFaZMqRo5fvoJpk2DQw+147feqho5\nHMepsUQZkpqFrX9wnYhcFttyLVi1YepU61WcH4zSxYaF8s2MGbBhA5x5Jmy9NbyZbIVKx3GcyhFF\nYXyNLVwTW0UstjlQPhx1/PH2ov7ss6qRo0sXWLIE+vaFXr2sh+FrnTiOk0Wi2DC2UNUr8iRP9eOM\nM6BbN9hpJ5gwAbbfvupkadrUfvv0gZdfhlmzYMdsLbftOE6xE8WG8bs8yVI9qVsXuncHEWjXDupU\nkYvKtdfCU0/Z/oknmgHelYXjOFkkypBUqYiMEJE/icixsS3nklUHli+HSy81hzmAmTPh4ovh66/z\nK0dZGdx3H3zyiR03aQItW+ZXBsdxajxRFEY9YCm2sP2RwdY3l0JVGz7+GO69FxYutOO1a+GBB8rt\nGvlizhxYuRK6di1Pe/ttOPlkm8XlOI6TBaJEq+2XD0GqJSUlNhTVo4cd77wzbL65+UOcemr+5Ij5\nX4QVxnffwZAhcPnlNmTmOI6TIUl7GCIyNLT/z7i8N3IpVLWhpAR22QW23NKO69SBXXctf4Hni0mT\noFYtkyVGr17269NrHcfJEqmGpDqE9g+Ky4u02EaNpqzMFMbee2+a3rWrKYx8TmldssSURf365Wkt\nWsBuu7kDn+M4WSOVwkj1xvMJ/t9+a0H+EimM9eth6dL8yfLwwzBx4q/Te/eG9983L3DHcZwMSWXD\naCAi3TClUj/Yl2Crn6JccbD99jZLasOGTdPPPRcuvNBsG/mkdoI/Ze/e8PrrMG8edOjw63zHcZw0\nEE0ydCIi76QqqKoH5kSiDOjevbsW3RKt778PN91kvYx4vwvV/Csux3GqFSIyUVUjzYxJOiSlqgem\n2iIKcqiIzBCRmSJyZYL8nUVkvIj8LCJXpFO2yjn5ZJtCm4hrroG//jU/cpSUwNix0Ljxr/NiyqKs\nLD+yOI5To4nih1EpgrAiDwKHAZ2Bk0Wkc9xpy7A1Nu6oRNmqY9UqGDoUFi9OnP/ll/Cf/+RHltJS\nGx5r1ixx/pAhZgBfvjw/8jiOU2PJmcIAegAzVXWWqq4DhgBHh09Q1e9V9RMgfom4CstWKRMm2Fd7\nvME7Rteu5u29YkXuZSkttVhWyWjVymZRvftu7mVxHKdGk0uF0QqYFzqeH6TlumzuiXlyxxz24ok5\n0OU6cu3atTB9+qYOe/HstRc0aODTax3HyZgKPb0BRKQVsEP4fFV9L1dCpYOInAucC9CmTZv8XLSk\nBDp2LI8OG0/sBV5aCvvvnzs5Fi+GPfaAPfdMfk7dutCzpzvwOY6TMRUqjMDL+0RsLe9YYCIFKlIY\nC4DWoePtg7QoRC6rqo8Aj4DNkopYf2Y0aVK+sl0iWra09SlyHcepTRtb7a8i+vSBK66wCLatCqej\n5jhO9SJKD+MYoJOq/pxm3Z8AHUSkHfayPwk4JQ9lc8+TT6bOF8l/eJBUHHaYRdKN9xlxHMdJgygK\nYxZQB0hLYajqBhG5CBgD1AIGq+oXIjIgyB8kItsCE4AtgTIRuRTorKorEpVN5/o5o6wMNsul6ScN\nDjnEfC8eeij1eZ07m5+G4zhOBkRRGGuwNTHeIqQ0VHVgRQVVdRQwKi5tUGh/ETbcFKlsQXDZZfDB\nBxbaPJVT3PvvQ79+MGyYxXTKNmVlJkenTtHPnzzZhsrcmc9xnEoQ5VN5BHAz8CEwMbQVJ+PHQ8OG\nFb90mza1YaBcDU3NnAmrV6eeIRXmiSds+u2MGbmRx3GcGk+FCkNVnwJeoFxRPB+kFR8//WShxJP5\nX4Tp2NGix+ZKYcTqTeWDEebAwDnfZ0s5jlNJKlQYInIA8BXmef0Q8KWI9MyxXIXJpEmJI9QmolYt\nG4rKpcKoXdvsE1Fo3x7atnV/DMdxKk2UIak7gYNV9feq2hM4BLg7t2IVKOPH2+9ee0U7v2tXUzK5\nWBujfXs480xb4S8qffrAO+/4bCnHcSpFFIVRR1V/GfhW1S+xWVPFR4cOcM45sN120c7v1QsOPhjW\nrMm+LGefDY8+ml6Z3r3hxx/h00+zL4/jODWepOHNfzlBZDBQBjwbJJ0K1FLV/jmWLW2KJrz5unXW\na0mndwGwbJnZMA45JHF0W8dxio6shDcPcT7m5T0w2KYGacXF6tXw/feVK5vtFe/eeQcaNYrm5R1m\n663hhBNcWTiOUymizJL6WVXvUtVjg+3uSnh9V39ef93ChCdaCjUV++9va2dkk9JSs0N07Jh+2W++\ngTvvtMCFjuM4aZBUYYjI0OB3iohMjt/yJ2KBUFJigfx23TW9cq1aZX+mVGkp7LADbLVV+mU//9zi\nSn3wQXZlchynxpPK0/uS4LdvPgQpeEpKLDJsunaDbt3gxRdtAaMmTbIjS2lpdIe9eHr2tOm4b75p\ns6Ycx3EikmqJ1oXB7gWqOje8ARfkR7wCYd06WzQpiv9FPNleG2P1avPWrqzCaNTI7sP9MRzHSZMo\nRu+DEqQdlm1BCprJk81wnYnCyNaw1Pr1cN11qcOrV0Tv3maL+eGH7MjkOE5RkMqGcb6ITAF2jrNf\nzAam5E/EAqBVK7j3XhvOSZcWLeDSS9O3fSSjSRO48cbKKa8YvXvbtNyPP86OTI7jFAVJ/TBEpDGw\nFfAP4MpQ1kpVXZYH2dKmKPwwZs6EZs0ys4esX2+9i222yZ5cjuNUS7Lih6GqP6rqHOBeYFnIfrFB\nRCLGxqghjBwJixZVvnxZmb3o16/PXJbTToNjjsmsjjp1Cl9ZrFhhU4AdxykYotgwHgZWhY5XBWnF\nweLFcNRR8Mwzla/j5ZctrMgXGa4BtXGj2VOiRqhNxaefQt++MH9+5nVlk7lzLZxKs2aw004wZkxV\nS+Q4TkAUhSEaGrdS1TKiLbxUM4h5U2diM+jSxX4zNXx/9ZU53FV2hlSYWrXgv/+t2tlSZWXwySdm\nxI/FxdpmG1PSl15qkXj/8AdbjMpxnConisKYJSIDRaROsF2CLdtaHIwfb34Le+xR+Tp22gkaNLDI\ntZmQ7hoYqdhtN2jevGrWxxg9Gs49F7bfHnr0gL//3aYtg60hMmkS3H47vPEGtG5tnumO41Q5UXoK\nA4D7gGsBBd4Czs2lUAVFSYn1EBo0qHwdtWpZHZn2MEpLzdt8550zqwdsXfJevayHoZrbZVu/+856\nEn0DH9Dbb7dpvYceasN9hx1mKxTGs8028O67lfNodxwn61SoMFT1e+CkPMhSeGzcaFNPzzgj87q6\ndoXnnsvs5XzCCaYs6tbNXB4wT+8XX4Rp06IvxBSVL76AESNs++gjU1Dff28BEJ9+2pRBFK/5WCj5\nH36wXsm//mULQeWTXCtUx6kmJFUYIvJ/qnq7iNyP9Sw2QVUH5lSyQkDEYi7Vr595XX/6ky28tGGD\nzVKqDLvvblu26N0bdtkFlizJXp0A99wDf/6z7e+5J9x0k/UkYj2F1q3Tr/Pbb6031KcP/O9/0dck\nyZTHH4crr4QLLoALLyz82WWOk0NS+WEcqaojRSTh53Uhrutdo/0wli835bXffoUfnnzJEnj4YTjr\nLGjZMnv1lpSYwmjXDsaNs95Krvj+e1MO69aZ4X30aOvZnXEGXH555SIFO04Bko4fRoULKFUnsq4w\nnn3WbBfHHpud+j77zGYGVcZoPXo0HH44vPeehUzPJhs22JDRZlHmQKRg1CjrtaQboDEd3n7b2qFL\nFzPYb7FFduv/+WeL5vvCC2Yz2n57S58xA+66C556ynqIixZBw4bZvbbjVAFZcdwTkZEiMiLZlj1x\nC5i//x0GD85efSefDDfcULmyMYP5b3+bPXnApqw2bWpG6Ux46ik44ojcz2jq1cvsLgsW2JZN5swx\nZfzAA9aTaNGiPK9TJ/j3v81PZMgQUxaqtmTvsGFm73KcGk6qT8o7gDuB2cBa4NFgWwV8nXvRqpjl\ny80YnIn/RTzdulV+ptSkSdC+ffaHozp1Mq/qTKbXDhsG/fvbcNHll2dPtmQcfbT5pOy8s720s/Gy\nHjnS/j5ffmn3c+ediW1NLVqYYgSb/fX223DccSbLww/7wlROjSZVaJBxqjoO+J2qnqiqI4PtFCDL\nYyIFSCww3z77ZK/Orl1h3jxYujT9spmsgZGK5s2t3so68L3xBpx0khn0hw/P7XBUmNhEhKuusgkF\nmSgNVRg0yGwjEyeazSIK225rCmboUDPoX3ABtGkDH35YeVkcJx3efNM+arM9cSUJUQatG4pI+9iB\niLQDav7g7fjxNktqzz2zV2dl18ZYudJiUeVCYYDZHT74ANasSa/c6tUW26pzZ7NfVMWY/lZbmb3h\nggvsxZ8OsWEtEZvy/OGHsOOO6dVRqxb88Y82dXjcODjwwPLIxOPH29/NcbLBunUwdiwMHFgegSI2\nxX7hwuTlskgUx70/A++KyCxAgB2A83IqVSEwebJNOd1yy+zVGQ4R0qtX9HL16tnLbNttsydLmD59\nbAjmgw/goETLnyShYUPzs2jXLnurCabLX/8KP/4I//iHDdf985/RfCbGjoVTT7VhqDFjMpdfxMLf\nh0PgDxxY3mM57DCbVNC2bfnf/tln7SUQJlV+p072NVmrVmayOtWHn36yWHQjR8Lrr9vwcf369i7Z\nay973kpK8iePqla4AZsDXYJt8yhlqmLbY489NGts3Kj63XfZqy/Gq6+qLliQ/XozYdUq1YsvVp0y\nJdr506erDh6cW5nSoaxM9cILVUH1lltSn7thg+oNN6iKqO6yi+rUqbmTa+FC1auvVm3SxGQD1eOP\nL88Pp0fNP+GE8vw1a3Inu1N1fPml6vjxtr96tWq9eqrbbqt6zjmqI0daWhYBJmjEd2yF02pFpAFw\nGbCDqp4jIh2ATqr6Wm5VWfrUWD+MYcMsntVRR1W1JDZLaL/9LFT79OlV17OIp6zMDO/77mse4YlY\nvBhOOcXGfU8/HR56KD/DaGvX2rXBvg6bN7f9efN+PYyWLL+szOxqzZpZD2ThQpsEccAB9lwceWT5\nFGCnerFxow1fjhxpPfbp0y12Xexd9tVXNlSa6bT3JGTVD0NEXgQmAqer6q6BAvlQVXM0oF55sqYw\nYiEt7roru0NSALNnw2uv2XTMevWildlzT5Mjl5FlN2604ZOdd05+z4sW2bTTJUtsvD7bU3wzJRzC\nY+nSX8enWrwYfvc789zu1696h/tYsMCez1dfha+DSYvdusH999s9ZoPVq82oP2OGbdtsA+efn526\nqzurVkGjRrZ/3XX2vghTp075C7+i/COPtHdC7dqbfgDkKQROVvwwQuyoqrcD6wFUdQ1my6i5jBpl\n44axByKbTJxoY9tR18bYsAGmTMlOhNpUfPSRjYmOHZs4f9kys28sXGhOhIWmLKBcAYwfb3aVYcPs\ny/zpp61H1Ly5tXv//tVbWYAtG3znnfb1OXWq2W4aNChXkqNG2ct99GgbB0/Gxo3mfzJmjH3hxth3\nX3v+d9/d/IduvNHG0MGUcc+eFhiy2Jgxw3qw221nPUCw56p9+023du3Ky1SUf/755lu0ZIn9/118\ncf7jpUWlojEr4EOgPvBpcLwj8HGU8S7gUGAGMBO4MkG+YJFwZwKTgd1DeXOwtcNLiTjGljUbRpcu\nqgcfnJ264vnqKxuLfuyxaOd//rmd/8wzuZEnxrp1qo0aqZ5/fuL8hx5SrVtXdezY3MqRDVatUt1n\nH9U6dVR79rT2e/rpqpYqv9xzj2rDhnbvDRuqHnus6tCh5flXXKG6666qm29ebh/p2LE8/7bbzB70\n0kuqn322qb3k009V27a1MqeearaamkxZmer//qd61FF2z5tvrnreearz51e1ZFkh6vtV7e4rfOkf\nBIwDFgPPBS/yAyKUq4U5+LUH6gKfAZ3jzjkcGB0ojr2Bj0J5c4BmUW9Es6UwVq5U3Wwz1euvz7yu\nRGzcqLrFFqoXXRTt/GeftT9TVIN0JvTtq9qhQ/L8L7/MvQzZYtkyU/x16qjef7/90xcba9eqjhql\nOmCAaqtWqi1alOddeqn9vS+/XPWRR1THjVNdtCh63atXq157rX1EbLml6n332bNdE/n6a/sf3Hpr\n1euuy81kmCokawojeJG3BpoCRwB9o77EgX2AMaHjq4Cr4s75N3By6HgGsJ1WpcJ45x1rllGjMq8r\nGfvtZ1sU/vIX+6JZvz538sS4+26797lz7XjdOtV+/VQnTcr9tXPBqlXl91LslJWpTp6cfcU5Y4bq\nQQep9upVc5Ty6tWqDz6oetll5WkjR9rzVANJR2GktGEElY1S1aWq+l9VfU1Vo7oUtgLmhY7nB2lR\nz1HgTRGZKCL5W7Bp6VLzd+jRI3fX6Nq1PBBhRdx6K3z+uRnEck3v3vb71ls2tn3GGfDEE+Ve79WN\nhg3N89oxm81uu2XfdtOxo9k/hg+3uufNMyfKykQzqGoWL7ZYb23aWCj78ePL/WD69vVgk0Qzen8q\nIll0d47MfmozsQ4DLhSRnolOEpFzRWSCiExYHJu6mAnHHWdrLyRaAS5bXHWVGSujTJOrU8eWeM0H\nu+4Kr7wCxxxj/zAvvGAOccmmqToOmKKIRQ0eNw4eecScDB9/PNpHUSEwdKgpiptuMoP/e++ZI2u2\nFiurIURRGHsBJSLytYhMFpEpIjI5QrkF2HBWjO2DtEjnqGrs93vgFSDhJ7+qPqKq3VW1e/PY/PVM\nyfUMmpYtN42EmoyFC+Gii2wWTD4QscB+t91mkVmvvNI2x4nKaadZoMzf/AbOPtt8djJdmjgXbNxo\nCiEWpmfPPU32qVNtCuz++1f/mXQ5IIrCOAQzXPcCjsTsGEdGKPcJ0EFE2olIXWyZ1/iw6COA08XY\nG/hRVReKSEMR2QJARBoCBwOfR7qjTJg9277mM4ncGpU77rCpdKmYMAEefNCWJ80XS5bYdQcMsPDu\njpMuu+1mX+hPPmmxtKryOfr5Z/tVhauvtjAtnTvbFOT99iuXrV07ePRRU3ROUlIt0VoPGADshE1v\nfVxVN0StWFU3iMhFwBhsxtRgVf1CRAYE+YOAUdhMqZnAGqBfULwF8IqYhq8NPK+qr6d5b+lTUmJO\nUM2a5fxSPP20dYFPPDH5OblaAyMVTZuao1HPnv6F5VQeEbOBHXVUuR1g+nT49FPz68jFs/Xf/5q9\nL+ZoOGOGDS+NGGHXe+klswV26mSOcbvskr3F0YqEVJbUpzBnvf9hdoTOwCXpVK6qozClEE4bFNpX\n4MIE5WZhcavyS0mJfXnEoo3mkq5dbS2FVJSWWo8n26vKpWKzzczb1HGyQWwdd7BQLPffbzaO7oFj\n8TbbwP/9n+0/+KD18sMky1+3zj7umjSxSMNgtsEpU8yprlMns0fuu295XTNm5Cy8RrGQSmF0VtXd\nAETkcaCaTpVJg/HjbSwzHzOSunaFZ56xmRnJbC+lpRZTxnFqAnffbcNBN99cHhajU6dyhfDqq79e\nSyRZfq1aNowUngU3fLiNDiQLbePKImNSvRnXx3aC4aU8iFOFrF1rxrp8rBgH5WtblJYmDim+dq3Z\nLnK1Bobj5Jtatcw2NmBA4vw33khdvqL89u1T5zsZk0phdBGRFcG+APWDY8FGk7Icla+KWbHCurAx\nX4Rc06WLjavOmpU4v359m8sev16C4zhOFZFUYahqca3S0qIFDBmSv+s1bWor6aVyBhLJ35KnjuM4\nFeCDejFeu+HqAAAKE0lEQVSWL8//NVMpi5tvhssuy58sjuM4FeAKI8ZuuyUfW80Vb74JRxyReC3t\n4cOjh0B3HMfJA64wAObPty3fTjsrVti6BZ/H+SSuX29pbvB2HKeAcIUBtngQwD775Pe6sUWR4kMn\nTJtmxm5XGI7jFBCpPL1XYhFjoXyFPaUmzpIqKTHjcr5f0G3b2pzxeIURO3aF4ThOAZFqllQe3Yur\nmJISW4oy35EpRUwpxCuMn382D++OHfMrj+M4TgoiDUmJyH4i0i/YbyYi7SoqU63o39/W0a0K9t7b\nHJpUy9POOcfCn9cqrpnNjuMUNqLhF1WiE0RuALoDnVS1o4i0BF5S1d/lQ8B06N69u06IhRxwHMdx\nKkREJqpq9yjnRulh/AE4ClgNoKrfAsUzXJVv5s614agxY6paEsdxnE2IojDWBVFlbZFvW5/CyRaq\n0KcP3HKLHZeWWhTOxo2rVi7HcZw4oiiMoSLyb6CJiJwDvAk8mluxiggRW7To/fftuLS0fP1lx3Gc\nAqLCON6qeoeIHASsADoC16vq2JxLVkx07QqvB+tDlZZaSGdfcN5xnAIjquPeFGwhpfeCfSebdO0K\n330HixaZwnD/C8dxCpAKFYaInI0tnnQscDxQIiL9cy1YURHz+J4wwabZJlofw3Ecp4qJsrTcX4Bu\nqroUQESaAh8Cg3MpWFHRpQvsv795m7/wQlVL4ziOk5AoCmMpsDJ0vDJIc7JFkybw3nvm4e04jlOg\npIolFVuMYSbwkYi8ik2tPRqYnAfZio+zzrIotfGhQhzHcQqAVDaMLYLta2A45YEIXwVm51iu4mPQ\nIHjuOfe/cBynYEkVfPDGfApS9DRrZr8eP8pxnAKlQhuGiDQH/g/YBagXS1fVXjmUq/iIrcUxcGDV\nyuE4jpOEKEbv54AXgb7AAOAMYHEuhSpKWrXaNGKt4zhOgRHFca+pqj4OrFfVcaraH/DeheM4TpER\npYexPvhdKCJHAN8CW+dOJMdxHKcQiaIwbhGRxsDlwP3AlsClOZXKcRzHKTgqXEApYSGRS1X1nhzI\nkxEishiYW8nizYAlWRSnOuNtsSneHpvi7VFOTWiLHVS1eZQTK6swvlHVNmkXLGBEZELUVadqOt4W\nm+LtsSneHuUUW1tEjVYbj2RVCsdxHKfgqazC8PmfjuM4RUaqWFIrSawYBKifM4mqjkeqWoACwtti\nU7w9NsXbo5yiaotK2TAcx3Gc4qOyQ1KO4zhOkVH0CkNEDhWRGSIyU0SurGp5coGItBaRd0Rkqoh8\nISKXBOlbi8hYEfkq+N0qVOaqoE1miMghofQ9RGRKkHefiFTbCRAiUktEJonIa8Fx0baHiDQRkZdF\nZLqITBORfYq1PUTkz8H/yeci8oKI1CvWtvgVqlq0G1ALC9/eHqgLfAZ0rmq5cnCf2wG7B/tbAF8C\nnYHbgSuD9CuBfwb7nYO22BxoF7RRrSDvY2BvzJY1Gjisqu8vg3a5DHgeeC04Ltr2AJ4Czg726wJN\nirE9gFbY8g31g+OhwJnF2BaJtmLvYfQAZqrqLFVdBwzBFoiqUajqQlX9NNhfCUzD/jGOxl4UBL/H\nBPtHA0NU9WdVnY0totVDRLYDtlTVErX/iKdDZaoVIrI9cATwWCi5KNsjiOTQE3gcQFXXqepyirQ9\nsMlA9UWkNtAAC4dUrG2xCcWuMFoB80LH84O0GouItAW6AR8BLVR1YZC1CGgR7Cdrl1bBfnx6deQe\nLGx/WSitWNujHRaB+olgiO4xEWlIEbaHqi4A7gC+ARYCP6rqGxRhWySi2BVGUSEijYD/AJeq6opw\nXvAVVBRT5kSkL/C9qk5Mdk4xtQf2Rb078LCqdgNWY8Muv1As7RHYJo7GlGhLoKGInBY+p1jaIhHF\nrjAWAK1Dx9sHaTUOEamDKYvnVHVYkPxd0HUm+P0+SE/WLguC/fj06sbvgKNEZA42DNlLRJ6leNtj\nPjBfVT8Kjl/GFEgxtkcfYLaqLlbV9cAwYF+Ksy1+RbErjE+ADiLSTkTqAicBI6pYpqwTzM54HJim\nqneFskZgC2IR/L4aSj9JRDYXkXZAB+DjoEu+QkT2Duo8PVSm2qCqV6nq9qraFvubv62qp1G87bEI\nmCcinYKk3sBUirM9vgH2FpEGwT30xmx+xdgWv6aqre5VvQGHY7OGvgauqWp5cnSP+2Fd6MlAabAd\nDjQF3gK+At4Etg6VuSZokxmEZncA3YHPg7wHCJw/q+sGHED5LKmibQ+gKzAheEaGA1sVa3sANwLT\ng/t4BpsBVZRtEb+5p7fjOI4TiWIfknIcx3Ei4grDcRzHiYQrDMdxHCcSrjAcx3GcSLjCcBzHcSLh\nCsOploiIBs52sePaIrI4FHn2KKkg+rCItBSRl4P9M0XkgTRluDrCOU+KyPHp1JtNRORdESmaNaed\n3OIKw6murAZ2FZHY6o8HEfKkVdURqnpbqgpU9VtVzeRlXqHCqM4Ewfcc5xdcYTjVmVFYxFmAk4EX\nYhnhHkPwlX+fiHwoIrNiX/wi0lZEPg/V1zr4Iv9KRG4I1TVcRCYGayScG6TdhkU0LRWR54K000Vk\nsoh8JiLPhOrtGX/tMIEc00Tk0eAab8QUYbiHICLNgnAmsfsbHqzNMEdELhKRy4LggSUisnXoEn8K\n5PxcRHoE5RuKyGAR+Tgoc3So3hEi8jbmqOY4v+AKw6nODMHCMtQDfotF4E3GdpjHe18gWc+jB3Bc\nUNcfQ0M5/VV1D8xzd6CINFXVK4G1qtpVVU8VkV2Aa4FeqtoFuCTNa3cAHlTVXYDlgRwVsStwLLAn\ncCuwRi144HgsFEWMBqraFbgAGBykXYOFROkBHAj8K4hQCxZH6nhV/X0EGZwiwhWGU21R1clAW6x3\nMaqC04erapmqTqU8NHU8Y1V1qaquxYLO7RekDxSRz4ASLNBchwRlewEvqeqSQLZlaV57tqqWBvsT\ng/uqiHdUdaWqLgZ+BEYG6VPiyr8QyPQesKWINAEOBq4UkVLgXaAe0CY4f2yc/I4DWFhjx6nOjMDW\nLzgAi/eTjJ9D+8mWyoyPk6MicgAWwXQfVV0jIu9iL9d0iHLt8DkbgZhtZgPlH3bx1w2XKQsdl7Hp\n//av7iuQ4zhVnRHOEJG9MPuQ4/wK72E41Z3BwI2qOiULdR0ktnZzfWx1tA+AxsAPgbLYGVtyM8b6\nIGw8wNvYMFZTsPXBsyAPwBxgj2C/sgb6EwFEZD9sQaAfgTHAxUEkVUSkW4ZyOkWAKwynWqOq81X1\nvixV9zG2Zshk4D+qOgF4HagtItMw+0NJ6PxHgMki8pyqfoHZEcYFw1d3kR3uAM4XkUlAs0rW8VNQ\nfhBwVpB2M1AHk/+L4NhxUuLRah3HcZxIeA/DcRzHiYQrDMdxHCcSrjAcx3GcSLjCcBzHcSLhCsNx\nHMeJhCsMx3EcJxKuMBzHcZxIuMJwHMdxIvH/uT96C9gFF1cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25024912ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the moving average loss to smooth out the noise in SGD\n",
    "plotdata[\"avgloss\"] = moving_average(plotdata[\"loss\"])\n",
    "plotdata[\"avgerror\"] = moving_average(plotdata[\"error\"])\n",
    "\n",
    "# Plot the training loss and the training error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.plot(plotdata[\"batchsize\"], plotdata[\"avgloss\"], 'b--')\n",
    "plt.xlabel('Minibatch number')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Minibatch run vs. Training loss')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(plotdata[\"batchsize\"], plotdata[\"avgerror\"], 'r--')\n",
    "plt.xlabel('Minibatch number')\n",
    "plt.ylabel('Label Prediction Error')\n",
    "plt.title('Minibatch run vs. Label Prediction Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluation / Testing \n",
    "\n",
    "Now that we have trained the network, let us evaluate the trained network on the test data. This is done using `trainer.test_minibatch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test error: 7.28%\n"
     ]
    }
   ],
   "source": [
    "# Read the training data\n",
    "reader_test = create_reader(test_file, False, input_dim, num_output_classes)\n",
    "\n",
    "test_input_map = {\n",
    "    label  : reader_test.streams.labels,\n",
    "    input  : reader_test.streams.features,\n",
    "}\n",
    "\n",
    "# Test data for trained model\n",
    "test_minibatch_size = 512\n",
    "num_samples = 10000\n",
    "num_minibatches_to_test = num_samples // test_minibatch_size\n",
    "test_result = 0.0\n",
    "\n",
    "for i in range(num_minibatches_to_test):\n",
    "    \n",
    "    # We are loading test data in batches specified by test_minibatch_size\n",
    "    # Each data point in the minibatch is a MNIST digit image of 784 dimensions \n",
    "    # with one pixel per dimension that we will encode / decode with the \n",
    "    # trained model.\n",
    "    data = reader_test.next_minibatch(test_minibatch_size,\n",
    "                                      input_map = test_input_map)\n",
    "\n",
    "    eval_error = trainer.test_minibatch(data)\n",
    "    test_result = test_result + eval_error\n",
    "\n",
    "# Average of evaluation errors of all test minibatches\n",
    "print(\"Average test error: {0:.2f}%\".format(test_result*100 / num_minibatches_to_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Note, this error is very comparable to our training error indicating that our model has good \"out of sample\" error a.k.a. generalization error. This implies that our model can very effectively deal with previously unseen observations (during the training process). This is key to avoid the phenomenon of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We have so far been dealing with aggregate measures of error. Let us now get the probabilities associated with individual data points. For each observation, the `eval` function returns the probability distribution across all the classes. The classifier is trained to recognize digits, hence has 10 classes. First let us route the network output through a `softmax` function. This maps the aggregated activations across the network to probabilities across the 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "out = C.softmax(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let us a small minibatch sample from the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read the data for evaluation\n",
    "reader_eval = create_reader(test_file, False, input_dim, num_output_classes)\n",
    "\n",
    "eval_minibatch_size = 25\n",
    "eval_input_map = {input: reader_eval.streams.features} \n",
    "\n",
    "data = reader_test.next_minibatch(eval_minibatch_size, input_map = test_input_map)\n",
    "\n",
    "img_label = data[label].asarray()\n",
    "img_data = data[input].asarray()\n",
    "predicted_label_prob = [out.eval(img_data[i]) for i in range(len(img_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Find the index with the maximum value for both predicted as well as the ground truth\n",
    "pred = [np.argmax(predicted_label_prob[i]) for i in range(len(predicted_label_prob))]\n",
    "gtlabel = [np.argmax(img_label[i]) for i in range(len(img_label))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label    : [4, 5, 6, 7, 8, 9, 7, 4, 6, 1, 4, 0, 9, 9, 3, 7, 8, 4, 7, 5, 8, 5, 3, 2, 2]\n",
      "Predicted: [4, 6, 6, 7, 5, 8, 7, 4, 6, 1, 4, 0, 4, 9, 3, 7, 1, 2, 7, 5, 8, 6, 3, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Label    :\", gtlabel[:25])\n",
    "print(\"Predicted:\", pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let us visualize some of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Label:  8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2502492a2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a random image\n",
    "sample_number = 5\n",
    "plt.imshow(img_data[sample_number].reshape(28,28), cmap=\"gray_r\")\n",
    "plt.axis('off')\n",
    "\n",
    "img_gt, img_pred = gtlabel[sample_number], pred[sample_number]\n",
    "print(\"Image Label: \", img_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Exploration Suggestion**\n",
    "-  Try exploring how the classifier behaves with different parameters - suggest changing the `minibatch_size` parameter from 25 to say 64 or 128. What happens to the error rate? How does the error compare to the logistic regression classifier?\n",
    "- Suggest trying to increase the number of sweeps\n",
    "- Can you change the network to reduce the training error rate? When do you see *overfitting* happening?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
