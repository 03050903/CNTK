{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual: How to create user minibatch sources\n",
    "\n",
    "In order to make use of CNTK’s training session, one has to provide the input data as an instance of [MinibatchSource](https://cntk.ai/pythondocs/cntk.io.html#cntk.io.MinibatchSource). Although [cntk.io](https://cntk.ai/pythondocs/cntk.io.html#module-cntk.io) already provides means to read image, text, and speech data, there might be the need (e.g. in distributed scnearios) to roll out one’s own custom minibatch source. This is possible in pure Python as simple matter of\n",
    "\n",
    "* inheriting from [UserMinibatchSource](https://cntk.ai/pythondocs/cntk.io.html#cntk.io.UserMinibatchSource), and\n",
    "* implementing the following methods\n",
    "    * *stream_infos()*: returns a list of [StreamInformation instances](https://cntk.ai/pythondocs/cntk.io.html#cntk.io.StreamInformation) that describe the streams the minibatch source is providing\n",
    "    * *next_minibatch()*: returns the next minibatch data as a dictionary of [StreamInformation](https://cntk.ai/pythondocs/cntk.io.html#cntk.io.StreamInformation) instance to the data (instance of [MinibatchData](https://cntk.ai/pythondocs/cntk.io.html#cntk.io.MinibatchData), which basically wraps the data).\n",
    "    \n",
    "In the following example, we demonstrate how to define a user minibatch source.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single node user minibatch source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='single_node_mb_source'></a>\n",
    "In the following MyDataSource example, the major steps are:\n",
    "\n",
    "* In MyDataSource constructor,\n",
    "    * prepare  state of the data loading: e.g. mark the initial location of data\n",
    "    * define  data stream information: e.g. StreamInformation(\"features\", ...) and StreamInformation(\"labels\",...)\n",
    "* Override the stream_infos() method to \n",
    "    * return the list of stream information: e.g. [self.fsi, self.lsi]\n",
    "* Override a next_minibath() method to \n",
    "    * based on the current accessing state of the data, retrieve the data for next minibatch and set data state for next minibatch retrieval: e.g. _prepare_nextbatch()\n",
    "    * wrap the retrieved data into a format that is convenient for CNTK internal usage: e.g. call cntk.Value constructors\n",
    "    * create a dictionary mapping stream information to the minibatch data: e.g. {self.fsi:  MinibatchData(f_data, ...), self.lsi: MinibatchData(l_data, ...)\n",
    "\n",
    "Note that in this example, for description simplicity we load the whole data set into the memory. In practice, the minibatch source should depend on the data source state (e.g. the mapping between the requesting next batch data and its logical/physical location in the data storage) to load (or pre-load) the data at the point (or right before) they are requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cntk as C\n",
    "from cntk.io import UserMinibatchSource, StreamInformation, MinibatchData\n",
    "\n",
    "# Our toy test data contains two sequences:\n",
    "# 1) the first column is the sequence ID: e.g. 0 is the ID for sequecne 0; and 1 is the ID for sequence 1, \n",
    "# 2) the second column is feature 'x' which is a sparse representation for the words in our training data, and\n",
    "# 3) the third column is our lable 'y' which is the one-hot representation of label.\n",
    "MBDATA = r'''0      |x 560:1        |y 1 0 0 0 0\n",
    "0   |x 0:1\n",
    "0   |x 0:1\n",
    "1   |x 560:1        |y 0 1 0 0 0\n",
    "1   |x 0:1\n",
    "1   |x 0:1\n",
    "1   |x 424:1\n",
    "'''\n",
    "\n",
    "class MyDataSource(UserMinibatchSource):\n",
    "    def __init__(self, f_dim, l_dim):\n",
    "        self.f_dim, self.l_dim = f_dim, l_dim\n",
    "\n",
    "        self._prepare_data()\n",
    "\n",
    "        #setting the state\n",
    "        self.fsi = StreamInformation(\"features\", 0, 'sparse', np.float32, (self.f_dim,))\n",
    "        self.lsi = StreamInformation(\"labels\", 1, 'dense', np.float32, (self.l_dim,))\n",
    "        self.sequences = sorted(self.data)\n",
    "        self.next_seq_idx = 0        \n",
    "        \n",
    "\n",
    "\n",
    "        super(MyDataSource, self).__init__()\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        \"\"\"\n",
    "        Parse the text and load the data into self.data. \n",
    "        self.data is of the following structure:\n",
    "           sequence id -> \"features\" -> list of features\n",
    "        and\n",
    "          sequence id -> \"labels\" -> label\n",
    "        \"\"\"\n",
    "        # MBDATA fits into memory, so we will read it in all at once. Normally, however,\n",
    "        # it does not, in which case we would need to keep track of the position in the\n",
    "        # file until which we have already provided the data.\n",
    "        # It follows the CNTKTextFormat specification\n",
    "        #   sequence ID |feature1 data |feature2 data\n",
    "        # where in this case feature1's data is encoded as one-hot and we will\n",
    "        # convert to CSR, and feature2's data is a one-hot encoded as dense.\n",
    "\n",
    "\n",
    "        self.data = {}\n",
    "        for line in MBDATA.split('\\n'):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            seq_id, data = line.split('|', 1)\n",
    "            data = data.split(\"|\")\n",
    "            seq_id = int(seq_id.strip())\n",
    "\n",
    "            if seq_id not in self.data:\n",
    "                self.data[seq_id] = {'features': []}\n",
    "\n",
    "            # Processing features - expecting one per line.\n",
    "            features = data[0].split(\" \")\n",
    "            vocab_idx = int(features[1].split(\":\")[0])\n",
    "            self.data[seq_id]['features'].append(vocab_idx)\n",
    "\n",
    "            # Process label, if exists\n",
    "            if len(data) == 2:\n",
    "                labels = np.asarray([data[1].split(\" \")[1:]], dtype=np.float32)\n",
    "                self.data[seq_id]['labels'] = labels\n",
    "    \n",
    "    def _prepare_nextbatch(self, num_samples):\n",
    "       # Note that in this example we do not yet make use of number_of_workers or\n",
    "        # worker_rank, which will limit the minibatch source to single GPU / single node\n",
    "        # scenarios.\n",
    "        features = []\n",
    "        labels = []\n",
    "\n",
    "        sweep_end = False\n",
    "\n",
    "        f_sample_count = l_sample_count = 0\n",
    "\n",
    "        while max(f_sample_count, l_sample_count) < num_samples:\n",
    "            if self.next_seq_idx == len(self.sequences):\n",
    "                sweep_end = True\n",
    "                self.next_seq_idx = 0\n",
    "\n",
    "            seq_id = self.sequences[self.sequences[self.next_seq_idx]]\n",
    "\n",
    "            f_data = self.data[seq_id]['features']\n",
    "            l_data = self.data[seq_id]['labels']\n",
    "            if (features or labels) and max(f_sample_count+len(f_data), l_sample_count+len(l_data)) > num_samples:\n",
    "                break\n",
    "            f_sample_count += len(f_data)\n",
    "            features.append(f_data)\n",
    "\n",
    "            l_sample_count += len(l_data)\n",
    "            labels.append(l_data)\n",
    "\n",
    "            self.next_seq_idx += 1\n",
    "        return features, f_sample_count, labels, l_sample_count, sweep_end\n",
    "        \n",
    "    def stream_infos(self):\n",
    "        \"\"\"\n",
    "        Override the stream_infos method of the base class --- UserMinibatchSource --- to provide stream meta information.\n",
    "        \"\"\"\n",
    "        return [self.fsi, self.lsi]\n",
    "\n",
    "    def next_minibatch(self, num_samples, number_of_workers=1, worker_rank=0, device=None):\n",
    "        \"\"\"\n",
    "        Override the next_minibatch method of the base class --- UserMinibatchSource --- to provide minibatch data.\n",
    "        \"\"\"\n",
    "        # Note that in this example we do not yet make use of number_of_workers or\n",
    "        # worker_rank, which will limit the minibatch source to single GPU / single node\n",
    "        # scenarios.\n",
    "        features, feature_sample_count, labels, label_sample_count, sweep_end = self._prepare_nextbatch(num_samples)\n",
    "        num_seq = len(features)\n",
    "\n",
    "        f_data = C.Value.one_hot(batch=features, num_classes=self.f_dim)\n",
    "        l_data = C.Value(batch=np.asarray(labels, dtype=np.float32))\n",
    "\n",
    "        result = {\n",
    "                self.fsi: MinibatchData(f_data, num_seq, feature_sample_count, sweep_end),\n",
    "                self.lsi: MinibatchData(l_data, num_seq, label_sample_count, sweep_end)\n",
    "                }\n",
    "\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the user minibatch data source in trainning sessions\n",
    "After we define a user minibatch source, such a minitbatch source can then be used wherever a MinibatchSource instance is accepted. For example, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate per sample: 0.5\n",
      "Finished Epoch[1 of 10]: [Training] loss = 1.077986 * 20, metric = 95.00% * 20 0.107s (186.9 samples/s);\n",
      "Finished Epoch[2 of 10]: [Training] loss = 0.424429 * 20, metric = 0.00% * 20 0.076s (263.2 samples/s);\n",
      "Finished Epoch[3 of 10]: [Training] loss = 0.082140 * 20, metric = 0.00% * 20 0.072s (277.8 samples/s);\n",
      "Finished Epoch[4 of 10]: [Training] loss = 0.030935 * 20, metric = 0.00% * 20 0.071s (281.7 samples/s);\n"
     ]
    }
   ],
   "source": [
    "input_dim = 1000\n",
    "num_output_classes = 5\n",
    "\n",
    "# instantiating the user minibatch source\n",
    "mbs = MyDataSource(input_dim, num_output_classes)\n",
    "feature = C.sequence.input_variable(shape=(input_dim,))\n",
    "label = C.input_variable(shape=(num_output_classes,))\n",
    "\n",
    "# setting up the model\n",
    "rnn = C.layers.Recurrence(C.layers.LSTM(20), go_backwards=False)(feature)\n",
    "end = C.sequence.last(rnn)\n",
    "z = C.layers.Dense(num_output_classes)(end)\n",
    "ce = C.cross_entropy_with_softmax(z, label)\n",
    "errs = C.classification_error(z, label)\n",
    "learner = C.sgd(z.parameters, C.learning_rate_schedule(0.5, unit = C.UnitType.sample) )\n",
    "\n",
    "# and train\n",
    "trainer = C.Trainer(z, (ce, errs), [learner], [C.logging.ProgressPrinter(tag='Training', num_epochs=10)])\n",
    "input_map = {\n",
    "    feature: mbs.fsi,\n",
    "    label: mbs.lsi\n",
    "}\n",
    "\n",
    "session = C.training_session(\n",
    "    trainer = trainer, \n",
    "    mb_source = mbs,\n",
    "    model_inputs_to_streams = input_map,\n",
    "    mb_size = 4, \n",
    "    max_samples = 80,\n",
    "    progress_frequency = 20\n",
    ")\n",
    "session.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Multiple node user minibatch source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define user minibatch source that can be used with distributed learners, e.g. BlockMomentum. We will need to use number_of_workers to cut the data in slices and then return the slices depending on which worker_rank requested the next minibatch.\n",
    "\n",
    "In the example below, we create a multi-worker data source. The difference between MyMultiWorkerDataSource below and the single node data source example [MyDataSource](#single_node_mb_source) is minimum:\n",
    "* Change _prepare_nextbatch(self, num_samples) to _prepare_nextbatch(self, num_samples, number_of_workers, worker_rank) to take into account the number of workers and the worker rank when preparing minibatch data: i.e. \n",
    "    * only the data that are supposed to be handled by the exact worker (identifed by the worker rank) will be returned\n",
    "* In next_minibatch(), provide workder number and worker rank to _prepare_nextbatch and then wrap the minibatch data in a CNTK internal representation in the same way as for single node minibatch data\n",
    "\n",
    "**Note that it is the user's resposibility to guarantee that 1) the data can be accessed in multiple nodes, 2) the data can be accessed in multi threads. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our toy test data contains two sequences:\n",
    "# 1) the first column is the sequence ID: e.g. 0 is the ID for sequecne 0; and 1 is the ID for sequence 1, \n",
    "# 2) the second column is feature 'x' which is a sparse representation for the words in our training data, and\n",
    "# 3) the third column is our lable 'y' which is the one-hot representation of label.\n",
    "MBDATA2 = r'''0      |x 560:1        |y 1 0 0 0 0\n",
    "0   |x 0:1\n",
    "0   |x 0:1\n",
    "1   |x 560:1        |y 0 1 0 0 0\n",
    "1   |x 0:1\n",
    "1   |x 0:1\n",
    "1   |x 424:1\n",
    "2   |x 160:1        |y 0 0 1 0 0\n",
    "2   |x 5:1\n",
    "2   |x 6:1\n",
    "3   |x 460:1        |y 0 0 0 1 0\n",
    "3   |x 3:1\n",
    "3   |x 3:1\n",
    "3   |x 425:1\n",
    "'''\n",
    "\n",
    "class MyMultiWorkerDataSource(UserMinibatchSource):\n",
    "    def __init__(self, f_dim, l_dim):\n",
    "        self.f_dim, self.l_dim = f_dim, l_dim\n",
    "\n",
    "        self._prepare_data()\n",
    "\n",
    "        #setting the state\n",
    "        self.fsi = StreamInformation(\"features\", 0, 'sparse', np.float32, (self.f_dim,))\n",
    "        self.lsi = StreamInformation(\"labels\", 1, 'dense', np.float32, (self.l_dim,))\n",
    "        self.sequences = sorted(self.data)\n",
    "        self.next_seq_idx = 0        \n",
    "        \n",
    "\n",
    "\n",
    "        super(MyMultiWorkerDataSource, self).__init__()\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        \"\"\"\n",
    "        Parse the text and load the data into self.data. \n",
    "        self.data is of the following structure:\n",
    "           sequence id -> \"features\" -> list of features\n",
    "        and\n",
    "          sequence id -> \"labels\" -> label\n",
    "        \"\"\"\n",
    "        # MBDATA fits into memory, so we will read it in all at once. Normally, however,\n",
    "        # it does not, in which case we would need to keep track of the position in the\n",
    "        # file until which we have already provided the data.\n",
    "        # It follows the CNTKTextFormat specification\n",
    "        #   sequence ID |feature1 data |feature2 data\n",
    "        # where in this case feature1's data is encoded as one-hot and we will\n",
    "        # convert to CSR, and feature2's data is a one-hot encoded as dense.\n",
    "\n",
    "\n",
    "        self.data = {}\n",
    "        for line in MBDATA2.split('\\n'):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            seq_id, data = line.split('|', 1)\n",
    "            data = data.split(\"|\")\n",
    "            seq_id = int(seq_id.strip())\n",
    "\n",
    "            if seq_id not in self.data:\n",
    "                self.data[seq_id] = {'features': []}\n",
    "\n",
    "            # Processing features - expecting one per line.\n",
    "            features = data[0].split(\" \")\n",
    "            vocab_idx = int(features[1].split(\":\")[0])\n",
    "            self.data[seq_id]['features'].append(vocab_idx)\n",
    "\n",
    "            # Process label, if exists\n",
    "            if len(data) == 2:\n",
    "                labels = np.asarray([data[1].split(\" \")[1:]], dtype=np.float32)\n",
    "                self.data[seq_id]['labels'] = labels\n",
    "    \n",
    "    def _prepare_nextbatch(self, num_samples, number_of_workers, worker_rank):\n",
    "        features = []\n",
    "        labels = []\n",
    "\n",
    "        sweep_end = False\n",
    "\n",
    "        f_sample_count = l_sample_count = 0\n",
    "\n",
    "        while max(f_sample_count, l_sample_count) < num_samples:\n",
    "            if self.next_seq_idx == len(self.sequences):\n",
    "                sweep_end = True\n",
    "                self.next_seq_idx = 0\n",
    "\n",
    "            seq_id = self.sequences[self.sequences[self.next_seq_idx]]\n",
    "            \n",
    "            #Based on the worker rank determines whether to add this data in the batch: \n",
    "            #If the sequences doesn't belong to this worker, skip it\n",
    "            #In practice, this should be done based on more efficient mechanism: e.g. based on the location of the worker\n",
    "            #and the data location\n",
    "            if (seq_id % number_of_workers) != worker_rank:\n",
    "                continue\n",
    "\n",
    "            f_data = self.data[seq_id]['features']\n",
    "            l_data = self.data[seq_id]['labels']\n",
    "            if (features or labels) and max(f_sample_count+len(f_data), l_sample_count+len(l_data)) > num_samples:\n",
    "                break\n",
    "            f_sample_count += len(f_data)\n",
    "            features.append(f_data)\n",
    "\n",
    "            l_sample_count += len(l_data)\n",
    "            labels.append(l_data)\n",
    "\n",
    "            self.next_seq_idx += 1\n",
    "        return features, f_sample_count, labels, l_sample_count, sweep_end\n",
    "        \n",
    "    def stream_infos(self):\n",
    "        \"\"\"\n",
    "        Override the stream_infos method of the base class --- UserMinibatchSource --- to provide stream meta information.\n",
    "        \"\"\"\n",
    "        return [self.fsi, self.lsi]\n",
    "\n",
    "    def next_minibatch(self, num_samples, number_of_workers, worker_rank, device=None):\n",
    "        \"\"\"\n",
    "        Override the next_minibatch method of the base class --- UserMinibatchSource --- to provide minibatch data.\n",
    "        \"\"\"\n",
    "        # Note that in this example we do not yet make use of number_of_workers or\n",
    "        # worker_rank, which will limit the minibatch source to single GPU / single node\n",
    "        # scenarios.\n",
    "        features, feature_sample_count, labels, label_sample_count, sweep_end = self._prepare_nextbatch(num_samples,\n",
    "                                                                                                        number_of_workers, \n",
    "                                                                                                        worker_rank)\n",
    "        num_seq = len(features)\n",
    "\n",
    "        f_data = C.Value.one_hot(batch=features, num_classes=self.f_dim)\n",
    "        l_data = C.Value(batch=np.asarray(labels, dtype=np.float32))\n",
    "\n",
    "        result = {\n",
    "                self.fsi: MinibatchData(f_data, num_seq, feature_sample_count, sweep_end),\n",
    "                self.lsi: MinibatchData(l_data, num_seq, label_sample_count, sweep_end)\n",
    "                }\n",
    "\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Using the user minibatch data source in trainning sessions\n",
    "After we define a user minibatch source, such a minitbatch source can then be used wherever a MinibatchSource instance is accepted. For example, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch[1 of 10]: [Training] loss = 1.612773 * 20, metric = 100.00% * 20 0.102s (196.1 samples/s);\n",
      "Finished Epoch[2 of 10]: [Training] loss = 0.995657 * 20, metric = 45.00% * 20 0.080s (250.0 samples/s);\n",
      "Finished Epoch[3 of 10]: [Training] loss = 0.378624 * 20, metric = 0.00% * 20 0.080s (250.0 samples/s);\n",
      "Finished Epoch[4 of 10]: [Training] loss = 0.109282 * 20, metric = 0.00% * 20 0.077s (259.7 samples/s);\n"
     ]
    }
   ],
   "source": [
    "input_dim = 1000\n",
    "num_output_classes = 5\n",
    "\n",
    "# instantiating the user minibatch source\n",
    "mbs = MyMultiWorkerDataSource(input_dim, num_output_classes)\n",
    "feature = C.sequence.input_variable(shape=(input_dim,))\n",
    "label = C.input_variable(shape=(num_output_classes,))\n",
    "\n",
    "# setting up the model\n",
    "rnn = C.layers.Recurrence(C.layers.LSTM(20), go_backwards=False)(feature)\n",
    "end = C.sequence.last(rnn)\n",
    "z = C.layers.Dense(num_output_classes)(end)\n",
    "ce = C.cross_entropy_with_softmax(z, label)\n",
    "errs = C.classification_error(z, label)\n",
    "local_learner = C.sgd(z.parameters, C.learning_rate_schedule(0.5, unit = C.UnitType.sample) )\n",
    "dist_learner = C.distributed.data_parallel_distributed_learner(local_learner)\n",
    "# and train\n",
    "trainer = C.Trainer(z, (ce, errs), [dist_learner], [C.logging.ProgressPrinter(tag='Training', num_epochs=10)])\n",
    "input_map = {\n",
    "    feature: mbs.fsi,\n",
    "    label: mbs.lsi\n",
    "}\n",
    "\n",
    "session = C.training_session(\n",
    "    trainer = trainer, \n",
    "    mb_source = mbs,\n",
    "    model_inputs_to_streams = input_map,\n",
    "    mb_size = 4, \n",
    "    max_samples = 80,\n",
    "    progress_frequency = 20\n",
    ")\n",
    "session.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
