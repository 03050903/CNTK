{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual: How to create user minibatch sources\n",
    "\n",
    "In order to make use of CNTKâ€™s (distributed) training functionality, one has to provide the input data as an instance of [MinibatchSource](https://cntk.ai/pythondocs/cntk.io.html#cntk.io.MinibatchSource). In CNTK, there are a variety of means to provide minibatch sources:\n",
    "\n",
    "- (**best**) convert data to the formats of built-in data readers - they support rich functionality of randomization/packing with high performance (see [Manual: How to feed data](https://github.com/Microsoft/CNTK/blob/master/Manual/Manual_How_to_feed_data.ipynb) and [cntk.io](https://cntk.ai/pythondocs/cntk.io.html))\n",
    "- (**preferred**) if it is hard to convert the data and the data can fit in memory, please use [MinibatchSourceFromData](https://cntk.ai/pythondocs/cntk.io.html?highlight=minibatchsourcefromdata#cntk.io.MinibatchSourceFromData), \n",
    "- if the data does not fit in memory and you want a fine grained control over how minibatch is created, then implementing the abstract  [UserMinibatchSource](https://cntk.ai/pythondocs/cntk.io.html#cntk.io.UserMinibatchSource) interfac is the option. \n",
    "\n",
    "This manual explains how to create user minibatch source in Python. A minibatch source is made to facilitate the CNTK training loops providing:\n",
    "1. meta-information regarding the data, such as *storage format*, *data type*, *shape of elements*,\n",
    "2. minibatch data, and\n",
    "3. auxiliary information for advanced features of the training loops, such as checkpoint state of the current access position of the data source so as to enable restoring interrupted training from the checking points.\n",
    "\n",
    "Correspondingly, in the minibatch source API, we need to implement the following methods:\n",
    "\n",
    "1. meta information for the learning loops regarding the data, e.g. *storage format*, *data type*, *shape of elements*  (see [StreamInformation](https://cntk.ai/pythondocs/cntk.io.html#cntk.io.StreamInformation) for details), \n",
    "2. next minibatch data when given the following parameters 1) *the number of samples*, 2) *the number of learning workers* which are working on the training in parrallel, 3) *the worker rank* which identifies which specific worker is requesting this minibatch data the outer learning loops when the outer loops \n",
    "3. implementing get_checkpoint_state() and restore_from_checkpoint(state) menthods so that the CNTK checkpoint mechanism can save the minibatch source states and restore the learning process from the save checkpoints without wasting time repeating training again (see [trainer checkpoint](https://cntk.ai/pythondocs/cntk.train.trainer.html?highlight=checkpoint#cntk.train.trainer.Trainer.restore_from_checkpoint) and [training session checkpiont config](https://cntk.ai/pythondocs/cntk.train.training_session.html?highlight=checkpoint#cntk.train.training_session.CheckpointConfig) for more information). \n",
    "\n",
    "All built-in and user minibatch data sources implement the above functionalties.\n",
    "\n",
    "## User minibatch source\n",
    "[UserMinibatchSource](https://cntk.ai/pythondocs/cntk.io.html#cntk.io.UserMinibatchSource) is an abstract interface enable end users to implement his/her own data minibatch data feeding mechanism. To implement a UserMinibatchSource, the user need to implement the following four methods to providing the minibatch source functionality described above:\n",
    "\n",
    "1. **stream_infos()**: return a dictionary mapping from names to state variable content\n",
    "2. **next_minibatch(num_samples, number_of_workers, worker_rank, device=None)**: return next minibatch of data given the outer learning loops provide the following parameters\n",
    "    * num_samples: the number of samples that are being requested \n",
    "    * num_of_workders: the number of workers in a distributed training session; if this is not a distributed training session, this number is always 1\n",
    "    * worker_rank: the number which identifies the specific worker who requests this minibatch in the distributed training setting; if this is not a distributed training session, the worker rank is always 0 (the first worker)\n",
    "    * device: a device descriptor specifying which device the minibatch data should be copied to, e.g. cntk.device.cpu() or cntk.device.gpu(device_id)  (see [DeviceDescriptor](https://cntk.ai/pythondocs/cntk.device.html#cntk.device.DeviceDescriptor) for details)\n",
    "3. **get_checkpoint_state()**\n",
    "4. **restore_from_checkpoint(state)**\n",
    "\n",
    "In the following example, we will detail the steps on how to implement the  [UserMinibatchSource](https://cntk.ai/pythondocs/cntk.io.html#cntk.io.UserMinibatchSource) interface. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single node user minibatch source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='single_node_mb_source'></a>\n",
    "In the following MyDataSource example, the major steps are:\n",
    "\n",
    "* In MyDataSource constructor,\n",
    "    * prepare  state of the data loading: e.g. mark the initial location of data\n",
    "    * define  data stream information: e.g. StreamInformation(\"features\", ...) and StreamInformation(\"labels\",...)\n",
    "* Override the stream_infos() method to \n",
    "    * return the list of stream information: e.g. [self.fsi, self.lsi]\n",
    "* Override a next_minibath() method to \n",
    "    * based on the current accessing state of the data, retrieve the data for next minibatch and set data state for next minibatch retrieval: e.g. _prepare_nextbatch()\n",
    "    * wrap the retrieved data into a format that is convenient for CNTK internal usage: e.g. call cntk.Value constructors\n",
    "    * create a dictionary mapping stream information to the minibatch data: e.g. {self.fsi:  MinibatchData(f_data, ...), self.lsi: MinibatchData(l_data, ...)\n",
    "\n",
    "Note that in this example, for description simplicity we load the whole data set into the memory. In practice, the minibatch source should depend on the data source state (e.g. the mapping between the requesting next batch data and its logical/physical location in the data storage) to load (or pre-load) the data at the point (or right before) they are requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cntk as C\n",
    "from cntk.io import UserMinibatchSource, StreamInformation, MinibatchData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Our toy test data contains two sequences:\n",
    "# 1) the first column is the sequence ID: e.g. 0 is the ID for sequecne 0; and 1 is the ID for sequence 1, \n",
    "# 2) the second column is feature 'x' which is a sparse representation for the words in our training data, and\n",
    "# 3) the third column is our lable 'y' which is the one-hot representation of label.\n",
    "MBDATA = r'''0      |x 560:1        |y 1 0 0 0 0\n",
    "0   |x 0:1\n",
    "0   |x 0:1\n",
    "1   |x 560:1        |y 0 1 0 0 0\n",
    "1   |x 0:1\n",
    "1   |x 0:1\n",
    "1   |x 424:1\n",
    "'''\n",
    "\n",
    "class MyDataSource(UserMinibatchSource):\n",
    "    def __init__(self, f_dim, l_dim):\n",
    "        self.f_dim, self.l_dim = f_dim, l_dim\n",
    "\n",
    "        self._prepare_data()\n",
    "\n",
    "        #setting the state\n",
    "        self.fsi = StreamInformation(\"features\", 0, 'sparse', np.float32, (self.f_dim,))\n",
    "        self.lsi = StreamInformation(\"labels\", 1, 'dense', np.float32, (self.l_dim,))\n",
    "        self.sequences = sorted(self.data)\n",
    "        self.next_seq_idx = 0        \n",
    "        \n",
    "\n",
    "\n",
    "        super(MyDataSource, self).__init__()\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        \"\"\"\n",
    "        Parse the text and load the data into self.data. \n",
    "        self.data is of the following structure:\n",
    "           sequence id -> \"features\" -> list of features\n",
    "        and\n",
    "          sequence id -> \"labels\" -> label\n",
    "        \"\"\"\n",
    "        # MBDATA fits into memory, so we will read it in all at once. Normally, however,\n",
    "        # it does not, in which case we would need to keep track of the position in the\n",
    "        # file until which we have already provided the data.\n",
    "        # It follows the CNTKTextFormat specification\n",
    "        #   sequence ID |feature1 data |feature2 data\n",
    "        # where in this case feature1's data is encoded as one-hot and we will\n",
    "        # convert to CSR, and feature2's data is a one-hot encoded as dense.\n",
    "\n",
    "\n",
    "        self.data = {}\n",
    "        for line in MBDATA.split('\\n'):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            seq_id, data = line.split('|', 1)\n",
    "            data = data.split(\"|\")\n",
    "            seq_id = int(seq_id.strip())\n",
    "\n",
    "            if seq_id not in self.data:\n",
    "                self.data[seq_id] = {'features': []}\n",
    "\n",
    "            # Processing features - expecting one per line.\n",
    "            features = data[0].split(\" \")\n",
    "            vocab_idx = int(features[1].split(\":\")[0])\n",
    "            self.data[seq_id]['features'].append(vocab_idx)\n",
    "\n",
    "            # Process label, if exists\n",
    "            if len(data) == 2:\n",
    "                labels = np.asarray([data[1].split(\" \")[1:]], dtype=np.float32)\n",
    "                self.data[seq_id]['labels'] = labels\n",
    "    \n",
    "    def _prepare_nextbatch(self, num_samples):\n",
    "       # Note that in this example we do not yet make use of number_of_workers or\n",
    "        # worker_rank, which will limit the minibatch source to single GPU / single node\n",
    "        # scenarios.\n",
    "        features = []\n",
    "        labels = []\n",
    "\n",
    "        sweep_end = False\n",
    "\n",
    "        f_sample_count = l_sample_count = 0\n",
    "\n",
    "        while max(f_sample_count, l_sample_count) < num_samples:\n",
    "            if self.next_seq_idx == len(self.sequences):\n",
    "                sweep_end = True\n",
    "                self.next_seq_idx = 0\n",
    "\n",
    "            seq_id = self.sequences[self.sequences[self.next_seq_idx]]\n",
    "\n",
    "            f_data = self.data[seq_id]['features']\n",
    "            l_data = self.data[seq_id]['labels']\n",
    "            if (features or labels) and max(f_sample_count+len(f_data), l_sample_count+len(l_data)) > num_samples:\n",
    "                break\n",
    "            f_sample_count += len(f_data)\n",
    "            features.append(f_data)\n",
    "\n",
    "            l_sample_count += len(l_data)\n",
    "            labels.append(l_data)\n",
    "\n",
    "            self.next_seq_idx += 1\n",
    "        return features, f_sample_count, labels, l_sample_count, sweep_end\n",
    "        \n",
    "    def stream_infos(self):\n",
    "        \"\"\"\n",
    "        Override the stream_infos method of the base class --- UserMinibatchSource --- to provide stream meta information.\n",
    "        \"\"\"\n",
    "        return [self.fsi, self.lsi]\n",
    "\n",
    "    def next_minibatch(self, num_samples, number_of_workers=1, worker_rank=0, device=None):\n",
    "        \"\"\"\n",
    "        Override the next_minibatch method of the base class --- UserMinibatchSource --- to provide minibatch data.\n",
    "        \"\"\"\n",
    "        # Note that in this example we do not yet make use of number_of_workers or\n",
    "        # worker_rank, which will limit the minibatch source to single GPU / single node\n",
    "        # scenarios.\n",
    "        features, feature_sample_count, labels, label_sample_count, sweep_end = self._prepare_nextbatch(num_samples)\n",
    "        num_seq = len(features)\n",
    "\n",
    "        f_data = C.Value.one_hot(batch=features, num_classes=self.f_dim)\n",
    "        l_data = C.Value(batch=np.asarray(labels, dtype=np.float32))\n",
    "\n",
    "        result = {\n",
    "                self.fsi: MinibatchData(f_data, num_seq, feature_sample_count, sweep_end),\n",
    "                self.lsi: MinibatchData(l_data, num_seq, label_sample_count, sweep_end)\n",
    "                }\n",
    "\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the user minibatch data source in trainning sessions\n",
    "After we define a user minibatch source, such a minitbatch source can then be used wherever a MinibatchSource instance is accepted. For example, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate per sample: 0.5\n",
      "Finished Epoch[1 of 10]: [Training] loss = 1.077986 * 20, metric = 95.00% * 20 0.107s (186.9 samples/s);\n",
      "Finished Epoch[2 of 10]: [Training] loss = 0.424429 * 20, metric = 0.00% * 20 0.076s (263.2 samples/s);\n",
      "Finished Epoch[3 of 10]: [Training] loss = 0.082140 * 20, metric = 0.00% * 20 0.072s (277.8 samples/s);\n",
      "Finished Epoch[4 of 10]: [Training] loss = 0.030935 * 20, metric = 0.00% * 20 0.071s (281.7 samples/s);\n"
     ]
    }
   ],
   "source": [
    "input_dim = 1000\n",
    "num_output_classes = 5\n",
    "\n",
    "# instantiating the user minibatch source\n",
    "mbs = MyDataSource(input_dim, num_output_classes)\n",
    "feature = C.sequence.input_variable(shape=(input_dim,))\n",
    "label = C.input_variable(shape=(num_output_classes,))\n",
    "\n",
    "# setting up the model\n",
    "rnn = C.layers.Recurrence(C.layers.LSTM(20), go_backwards=False)(feature)\n",
    "end = C.sequence.last(rnn)\n",
    "z = C.layers.Dense(num_output_classes)(end)\n",
    "ce = C.cross_entropy_with_softmax(z, label)\n",
    "errs = C.classification_error(z, label)\n",
    "learner = C.sgd(z.parameters, C.learning_rate_schedule(0.5, unit = C.UnitType.sample) )\n",
    "\n",
    "# and train\n",
    "trainer = C.Trainer(z, (ce, errs), [learner], [C.logging.ProgressPrinter(tag='Training', num_epochs=10)])\n",
    "input_map = {\n",
    "    feature: mbs.fsi,\n",
    "    label: mbs.lsi\n",
    "}\n",
    "\n",
    "session = C.training_session(\n",
    "    trainer = trainer, \n",
    "    mb_source = mbs,\n",
    "    model_inputs_to_streams = input_map,\n",
    "    mb_size = 4, \n",
    "    max_samples = 80,\n",
    "    progress_frequency = 20\n",
    ")\n",
    "session.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Multiple node user minibatch source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define user minibatch source that can be used with distributed learners, e.g. BlockMomentum. We will need to use number_of_workers to cut the data in slices and then return the slices depending on which worker_rank requested the next minibatch.\n",
    "\n",
    "In the example below, we create a multi-worker data source. The difference between MyMultiWorkerDataSource below and the single node data source example [MyDataSource](#single_node_mb_source) is minimum:\n",
    "* Change _prepare_nextbatch(self, num_samples) to _prepare_nextbatch(self, num_samples, number_of_workers, worker_rank) to take into account the number of workers and the worker rank when preparing minibatch data: i.e. \n",
    "    * only the data that are supposed to be handled by the exact worker (identifed by the worker rank) will be returned\n",
    "* In next_minibatch(), provide workder number and worker rank to _prepare_nextbatch and then wrap the minibatch data in a CNTK internal representation in the same way as for single node minibatch data\n",
    "\n",
    "**Note that it is the user's resposibility to guarantee that 1) the data can be accessed in multiple nodes, 2) the data can be accessed in multiple threads. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our toy test data contains two sequences:\n",
    "# 1) the first column is the sequence ID: e.g. 0 is the ID for sequecne 0; and 1 is the ID for sequence 1, \n",
    "# 2) the second column is feature 'x' which is a sparse representation for the words in our training data, and\n",
    "# 3) the third column is our lable 'y' which is the one-hot representation of label.\n",
    "sample_data = r'''0      |x 560:1        |y 1 0 0 0 0\n",
    "0   |x 0:1\n",
    "0   |x 0:1\n",
    "1   |x 560:1        |y 0 1 0 0 0\n",
    "1   |x 0:1\n",
    "1   |x 0:1\n",
    "1   |x 424:1\n",
    "2   |x 160:1        |y 0 0 1 0 0\n",
    "2   |x 5:1\n",
    "2   |x 6:1\n",
    "3   |x 460:1        |y 0 0 0 1 0\n",
    "3   |x 3:1\n",
    "3   |x 3:1\n",
    "3   |x 425:1\n",
    "'''\n",
    "\n",
    "class MyMultiWorkerDataSource(UserMinibatchSource):\n",
    "    def __init__(self, file_io, f_dim, l_dim):\n",
    "        self.f_dim, self.l_dim = f_dim, l_dim\n",
    "        self.file_io = file_io\n",
    "        \n",
    "\n",
    "        #setting the state\n",
    "        self.fsi = StreamInformation(\"features\", 0, 'sparse', np.float32, (self.f_dim,))\n",
    "        self.lsi = StreamInformation(\"labels\", 1, 'dense', np.float32, (self.l_dim,))\n",
    "        self.io_pos = self.file_io.tell()\n",
    "        super(MyMultiWorkerDataSource, self).__init__()\n",
    "\n",
    "    def _parse_line(self, line):\n",
    "        res = {}\n",
    "        seq_id, data = line.split('|', 1)\n",
    "        seq_id = int(seq_id.strip())\n",
    "        data = data.split(\"|\")        \n",
    "        # Processing features - expecting one per line.\n",
    "        features = data[0].split(\" \")\n",
    "        vocab_idx = int(features[1].split(\":\")[0])\n",
    "        features = vocab_idx\n",
    "        # Process label, if exists\n",
    "        if len(data) == 2:\n",
    "            labels = np.asarray([data[1].split(\" \")[1:]], dtype=np.float32)\n",
    "        else:\n",
    "            labels = None\n",
    "        return seq_id, features, labels\n",
    "        \n",
    "    def _prepare_nextbatch(self, num_samples, number_of_workers, worker_rank):\n",
    "        features = []\n",
    "        labels = []\n",
    "\n",
    "        sweep_end = False\n",
    "\n",
    "        f_sample_count = l_sample_count = 0\n",
    "\n",
    "        seq_id = -1\n",
    "        feature_data = []\n",
    "        label_data = None\n",
    "\n",
    "        #seek to the previous reading location:\n",
    "        self.file_io.seek(self.io_pos)\n",
    "        while max(f_sample_count, l_sample_count) < num_samples:\n",
    "            io_pos = self.file_io.tell()\n",
    "            line = self.file_io.readline()\n",
    "            if \"\" == line:\n",
    "                sweep_end = True\n",
    "                #rewind to the begining\n",
    "                self.file_io.seek(0)\n",
    "                seq_id = -1\n",
    "                continue\n",
    "                \n",
    "            next_seq_id, next_feature, next_label = self._parse_line(line)\n",
    "            if seq_id != next_seq_id:\n",
    "                if seq_id != -1:\n",
    "                    #a sequence is ready:\n",
    "                    #Based on the worker rank, determines whether to add this data in the batch: \n",
    "                    #If the sequences doesn't belong to this worker, skip it\n",
    "                    #In practice, this should be  based on more efficient mechanism: e.g. based on the location of the worker\n",
    "                    #and the data location\n",
    "                    print('io pos: ', io_pos)\n",
    "                    print('seq_id:', seq_id)\n",
    "                    print('workder_rank: ', worker_rank)\n",
    "                    print('feature_data: ', feature_data)\n",
    "                    #if (seq_id % number_of_workers) != worker_rank:\n",
    "                    #    continue\n",
    "\n",
    "                    if (feature_data or label_data) and max(f_sample_count+len(feature_data), l_sample_count+len(label_data)) > num_samples:\n",
    "                        print('===two much sample; reserve for next batch== ')\n",
    "                        print('save io pos: ', self.io_pos)                        \n",
    "                        break\n",
    "                    f_sample_count += len(feature_data)\n",
    "                    features.append(feature_data)\n",
    "                    l_sample_count += len(label_data)\n",
    "                    labels.append(label_data)\n",
    "                #start a new sequence\n",
    "                seq_id = next_seq_id\n",
    "                feature_data = [next_feature]\n",
    "                label_data = next_label\n",
    "                #record the start io pos of this sequence for the future when restart is needed\n",
    "                self.io_pos = io_pos\n",
    "\n",
    "            else:    \n",
    "                #continue the previous sequence\n",
    "                feature_data.append(next_feature)\n",
    "                if next_label is not None:\n",
    "                    label_data = next_label\n",
    "                \n",
    "\n",
    "        return features, f_sample_count, labels, l_sample_count, sweep_end\n",
    "        \n",
    "    def stream_infos(self):\n",
    "        \"\"\"\n",
    "        Override the stream_infos method of the base class --- UserMinibatchSource --- to provide stream meta information.\n",
    "        \"\"\"\n",
    "        return [self.fsi, self.lsi]\n",
    "\n",
    "    def next_minibatch(self, num_samples, number_of_workers, worker_rank, device=None):\n",
    "        \"\"\"\n",
    "        Override the next_minibatch method of the base class --- UserMinibatchSource --- to provide minibatch data.\n",
    "        \"\"\"\n",
    "        features, feature_sample_count, labels, label_sample_count, sweep_end = self._prepare_nextbatch(num_samples,\n",
    "                                                                                                        number_of_workers, \n",
    "                                                                                                        worker_rank)\n",
    "        num_seq = len(features)\n",
    "\n",
    "        print('features to training: ', features)\n",
    "        f_data = C.Value.one_hot(batch=features, num_classes=self.f_dim)\n",
    "        l_data = C.Value(batch=np.asarray(labels, dtype=np.float32))\n",
    "\n",
    "        result = {\n",
    "                self.fsi: MinibatchData(f_data, num_seq, feature_sample_count, sweep_end),\n",
    "                self.lsi: MinibatchData(l_data, num_seq, label_sample_count, sweep_end)\n",
    "                }\n",
    "\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "features to training:  [[560, 0, 0], [560, 0, 0, 424]]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "===two much sample; reserve for next batch== \n",
      "save io pos:  58\n",
      "features to training:  [[160, 5, 6], [560, 0, 0]]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "features to training:  [[560, 0, 0, 424], [160, 5, 6]]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "features to training:  [[560, 0, 0], [560, 0, 0, 424]]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "===two much sample; reserve for next batch== \n",
      "save io pos:  58\n",
      "features to training:  [[160, 5, 6], [560, 0, 0]]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "features to training:  [[560, 0, 0, 424], [160, 5, 6]]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "features to training:  [[560, 0, 0], [560, 0, 0, 424]]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "===two much sample; reserve for next batch== \n",
      "save io pos:  58\n",
      "features to training:  [[160, 5, 6], [560, 0, 0]]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "features to training:  [[560, 0, 0, 424], [160, 5, 6]]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "features to training:  [[560, 0, 0], [560, 0, 0, 424]]\n",
      "Finished Epoch[1 of 10]: [Training] loss = 1.303856 * 20, metric = 60.00% * 20 0.070s (285.7 samples/s);\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "===two much sample; reserve for next batch== \n",
      "save io pos:  58\n",
      "features to training:  [[160, 5, 6], [560, 0, 0]]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "features to training:  [[560, 0, 0, 424], [160, 5, 6]]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "features to training:  [[560, 0, 0], [560, 0, 0, 424]]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "===two much sample; reserve for next batch== \n",
      "save io pos:  58\n",
      "features to training:  [[160, 5, 6], [560, 0, 0]]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "features to training:  [[560, 0, 0, 424], [160, 5, 6]]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "features to training:  [[560, 0, 0], [560, 0, 0, 424]]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "===two much sample; reserve for next batch== \n",
      "save io pos:  58\n",
      "features to training:  [[160, 5, 6], [560, 0, 0]]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "features to training:  [[560, 0, 0, 424], [160, 5, 6]]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "features to training:  [[560, 0, 0], [560, 0, 0, 424]]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "===two much sample; reserve for next batch== \n",
      "save io pos:  58\n",
      "features to training:  [[160, 5, 6], [560, 0, 0]]\n",
      "Finished Epoch[2 of 10]: [Training] loss = 0.622769 * 20, metric = 15.00% * 20 0.047s (425.5 samples/s);\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "features to training:  [[560, 0, 0, 424], [160, 5, 6]]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "features to training:  [[560, 0, 0], [560, 0, 0, 424]]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "===two much sample; reserve for next batch== \n",
      "save io pos:  58\n",
      "features to training:  [[160, 5, 6], [560, 0, 0]]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "features to training:  [[560, 0, 0, 424], [160, 5, 6]]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "features to training:  [[560, 0, 0], [560, 0, 0, 424]]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "===two much sample; reserve for next batch== \n",
      "save io pos:  58\n",
      "features to training:  [[160, 5, 6], [560, 0, 0]]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "features to training:  [[560, 0, 0, 424], [160, 5, 6]]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "features to training:  [[560, 0, 0], [560, 0, 0, 424]]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "===two much sample; reserve for next batch== \n",
      "save io pos:  58\n",
      "features to training:  [[160, 5, 6], [560, 0, 0]]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "features to training:  [[560, 0, 0, 424], [160, 5, 6]]\n",
      "Finished Epoch[3 of 10]: [Training] loss = 0.227930 * 20, metric = 0.00% * 20 0.056s (357.1 samples/s);\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "features to training:  [[560, 0, 0], [560, 0, 0, 424]]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "===two much sample; reserve for next batch== \n",
      "save io pos:  58\n",
      "features to training:  [[160, 5, 6], [560, 0, 0]]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "features to training:  [[560, 0, 0, 424], [160, 5, 6]]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "features to training:  [[560, 0, 0], [560, 0, 0, 424]]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "===two much sample; reserve for next batch== \n",
      "save io pos:  58\n",
      "features to training:  [[160, 5, 6], [560, 0, 0]]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "features to training:  [[560, 0, 0, 424], [160, 5, 6]]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "features to training:  [[560, 0, 0], [560, 0, 0, 424]]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "features to training:  [[160, 5, 6], [560, 0, 0]]\n",
      "io pos:  126\n",
      "seq_id: 1\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0, 424]\n",
      "features to training:  [[560, 0, 0, 424]]\n",
      "io pos:  181\n",
      "seq_id: 2\n",
      "workder_rank:  0\n",
      "feature_data:  [160, 5, 6]\n",
      "features to training:  [[160, 5, 6]]\n",
      "io pos:  58\n",
      "seq_id: 0\n",
      "workder_rank:  0\n",
      "feature_data:  [560, 0, 0]\n",
      "===two much sample; reserve for next batch== \n",
      "save io pos:  0\n",
      "features to training:  []\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\local\\anaconda3-4.1.1-windows-x86_64\\envs\\cntk-py35r\\lib\\site-packages\\cntk\\io\\__init__.py\u001b[0m in \u001b[0;36m_next_minibatch\u001b[1;34m(self, info_map, mb_size_in_sequences, mb_size_in_samples, number_of_workers, worker_rank, device)\u001b[0m\n\u001b[0;32m    425\u001b[0m         \u001b[1;31m# mbsize_in_sequences is ignored\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m         \u001b[0mmb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmb_size_in_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_workers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworker_rank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m         \u001b[0minfo_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-73-744b2626cdf3>\u001b[0m in \u001b[0;36mnext_minibatch\u001b[1;34m(self, num_samples, number_of_workers, worker_rank, device)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'features to training: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mf_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mValue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[0ml_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\local\\anaconda3-4.1.1-windows-x86_64\\envs\\cntk-py35r\\lib\\site-packages\\cntk\\internal\\swig_helper.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mmap_if_possible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\local\\anaconda3-4.1.1-windows-x86_64\\envs\\cntk-py35r\\lib\\site-packages\\cntk\\core.py\u001b[0m in \u001b[0;36mone_hot\u001b[1;34m(batch, num_classes, dtype, device)\u001b[0m\n\u001b[0;32m    531\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'input must be a list'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m         \u001b[0mremove_sequence_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "SWIG director method error.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-8fac1fb9b266>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mprogress_frequency\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m )\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\local\\anaconda3-4.1.1-windows-x86_64\\envs\\cntk-py35r\\lib\\site-packages\\cntk\\internal\\swig_helper.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mmap_if_possible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\local\\anaconda3-4.1.1-windows-x86_64\\envs\\cntk-py35r\\lib\\site-packages\\cntk\\train\\training_session.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    274\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_default_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrainingSession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_cross_validation_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage_error\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_minibatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\local\\anaconda3-4.1.1-windows-x86_64\\envs\\cntk-py35r\\lib\\site-packages\\cntk\\cntk_py.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, computeDevice)\u001b[0m\n\u001b[0;32m   2996\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2997\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomputeDevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2998\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_cntk_py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrainingSession_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomputeDevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3000\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrestore_from_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpointFileName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: SWIG director method error."
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "input_dim = 1000\n",
    "num_output_classes = 5\n",
    "\n",
    "# instantiating the user minibatch source\n",
    "file_io =  io.StringIO(sample_data) #mock the string data as file io for self-contained explanation purpurse\n",
    "mbs = MyMultiWorkerDataSource(file_io, input_dim, num_output_classes)\n",
    "feature = C.sequence.input_variable(shape=(input_dim,))\n",
    "label = C.input_variable(shape=(num_output_classes,))\n",
    "\n",
    "# setting up the model\n",
    "rnn = C.layers.Recurrence(C.layers.LSTM(20), go_backwards=False)(feature)\n",
    "end = C.sequence.last(rnn)\n",
    "z = C.layers.Dense(num_output_classes)(end)\n",
    "loss = C.cross_entropy_with_softmax(z, label)\n",
    "errs = C.classification_error(z, label)\n",
    "local_learner = C.sgd(z.parameters, C.learning_rate_schedule(0.5, unit = C.UnitType.sample) )\n",
    "dist_learner = C.distributed.data_parallel_distributed_learner(local_learner)\n",
    "# and train\n",
    "trainer = C.Trainer(z, (loss, errs), [dist_learner], [C.logging.ProgressPrinter(tag='Training', num_epochs=10)])\n",
    "input_map = {\n",
    "    feature: mbs.fsi,\n",
    "    label: mbs.lsi\n",
    "}\n",
    "session = C.training_session(\n",
    "    trainer = trainer, \n",
    "    mb_source = mbs,\n",
    "    model_inputs_to_streams = input_map,\n",
    "    mb_size = 7, \n",
    "    max_samples = 80,\n",
    "    progress_frequency = 20\n",
    ")\n",
    "session.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the user minibatch data source in trainning sessions with distributed learners\n",
    "After we define a user minibatch source which takes into accoun ther worker number and worker rank, such a minitbatch source can then be used wherever a MinibatchSource instance is accepted. For example, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#finalize the distributed learning\n",
    "C.distributed.Communicator.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
