{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On Learner and Trainer APIs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let us lay out the notations and popular SGD algorithms in the literature. Let $l(w_t, x_i)$ be the loss function of sample $x_i$ at parameter weights $w_t$. In the literature, the loss are estimated with empirical loss over a data set $X$: \n",
    "$$\n",
    "L(w_t; X) = \\frac{1}{|X|}\\sum_{x_i \\in X} l(w_t, x_i)\n",
    "$$\n",
    "To parallelize the computation, we usually make use of its addictive structure and move $\\frac{1}{|X|}$ inside the summation:\n",
    "$$\n",
    "L(w_t; X) = \\sum_{x_i \\in X} \\frac{1}{|X|} l(w_t, x_i)\n",
    "$$\n",
    "**Note that the difference between the formulas in the literature and that are used in the computation usually causes confusion over the configuration of various optimization algorithms' parameters.**\n",
    "\n",
    "## Stochastic gradient descent and its variance:\n",
    "\n",
    "* Stochastic SGD, let $\\eta$ be the learning rate, randomly sample $x_i$ from data set $X$:   \n",
    "\n",
    "$$w_t = w_{t-1} -  \\nabla_{w_t} \\eta l(w_t, x_i)$$ \n",
    "\n",
    "* Stochastic minibatch SGD, randomaly sample a minibatch $B_j \\subseteq X$:\n",
    "\n",
    "$$w_t = w_{t-1} - \\sum_{x_i \\in B_j} \\eta  \\frac{1}{|B_j|} \\nabla_{w_t} l(w_t, x_i)$$ \n",
    "\n",
    "* Stochastic momentent SGD: Let $\\gamma$ be the momentum rate\n",
    "\n",
    "    In the literature, $$\n",
    "\\begin{align}\n",
    "u_t &= \\gamma u_{t-1} + \\sum_{x_i \\in B_j} \\frac{1}{|B_j|}\\nabla_{w_t} l(w_t, x_i) \\\\\n",
    "w_t &= w_{t-1} - \\eta u_t\n",
    "\\end{align}\n",
    "$$ \n",
    "Let $\\gamma' = \\gamma  \\eta$, we have the formulas in a more addictively computable form:\n",
    "$$\n",
    "\\begin{align}\n",
    "v_t &= \\gamma' v_{t-1} + \\sum_{x_i \\in B_j} \\eta \\frac{1}{|B_j|}\\nabla_{w_t} l(w_t, x_i) \\\\\n",
    "w_t &= w_{t-1} -  v_t\n",
    "\\end{align}\n",
    "$$ \n",
    "\n",
    "* ADAM (and other stochastic SGDs with both momentum and 2nd momentum  involved): \n",
    "\n",
    "    Let $g_t = \\sum_{x_i \\in B} \\frac{1}{|B|} \\nabla_{w_t} l(w_t, x_i)$, and $g^2_t = g_t \\odot g_t$ ($\\odot$ i element-wise product operator of vectors)\n",
    "    $$\\begin{align}\n",
    "    m_t &= \\beta_1 m_{t-1} + (1 - \\beta_1) g_t\\\\\n",
    "    v_t &= \\beta_2 v_{t-1} + (1 - \\beta_2) g^2_t\\\\\n",
    "    \\hat{m_t} &= m_t / (1 - \\beta^t_1)\\\\\n",
    "    \\hat{v_t} &= v_t / (1 - \\beta^t_2)\\\\\n",
    "    w_{t} & = w_{t-1} - \\eta \\hat{m}_t \\oslash (\\hat{v}_t^{\\frac{1}{2}} + \\epsilon) \n",
    "    \\end{align}$$ where $\\oslash$ is element-wise division and $\\hat{v}_t^{\\frac{1}{2}}$ is element-wise square root operator. To distribute the batch dependent term $\\frac{1}{|B|}$ into individual sample $x_i$, we need to rewrite the above equations into:\n",
    "\t$$\\begin{align}\n",
    "\tm_t & = \\beta_1 m_{t-1} + \\sum_{x_i \\in B} (1 - \\beta_1)\\frac{1}{|B|} \\nabla_{w_t} l(w_t, x_i)\\\\\n",
    "\tv_t &= \\beta_2 v_{t-1} + \\sum_{x_i \\in B} (1 - \\beta_2)  \\frac{1}{|B|^2} [\\nabla_{w_t} l(w_t, x_i) \\odot \\nabla_{w_t} l(w_t, x_i)] \\\\\n",
    "\t\\hat{m_t} &= m_t / (1 - \\beta^t_1)\\\\\n",
    "\t\\hat{v_t} &= v_t / (1 - \\beta^t_2)\\\\\n",
    "\tw_{t} & = w_{t-1} - \\eta \\hat{m}_t \\oslash (\\hat{v}_t^{\\frac{1}{2}} + \\epsilon) \n",
    "\t\\end{align}$$\n",
    "\n",
    "\n",
    "\n",
    "**TODO: 1) fill in equations for CNTK distributed training and their corresonding equations in the literature; 2) fill in equations for other implemented algorithms and their corresonding equations in the literature. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regarding regularization terms\n",
    "For example, if L2-regularization is applied, the regularized loss function: \n",
    "$$\n",
    " ll(w_t, x) = \\frac{\\lambda}{2}||w_t||^2 + l(w_t, x)\n",
    "$$\n",
    "Its gradient is \n",
    "$$\n",
    "\\nabla_{w_t}ll(w_t, x) = \\lambda_{w_t} w_t + \\nabla_{w_t} l(w_t, x)\n",
    "$$\n",
    "* The corresonding SGD update is \n",
    "    $$w_t = w_{t-1} - \\eta \\lambda w_t - \\nabla_{w_t} \\eta l(w_t, x_i)$$ \n",
    "* The corresponiding minibatch SGD update is:\n",
    "$$\n",
    "\\begin{align}\n",
    "    w_t &= w_{t-1}  - \\sum_{x_i \\in B_j}  (\\frac{1}{|B_j|} \\eta) \\lambda w_t - \\sum_{x_i \\in B_j} (\\frac{1}{|B_j|} \\eta)   \\nabla_{w_t} l(w_t, x_i) \\\\\n",
    "        &= w_{t-1}  -   \\lambda w_t - \\sum_{x_i \\in B_j}\\frac{1}{|B_j|} \\eta   \\nabla_{w_t} l(w_t, x_i) \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**We need to be careful about how the learning rate and minibatch size is handled in the update. From the above, either way will work but don't mix them.** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The API reqirement for learners\n",
    " \n",
    "Key observations:\n",
    "1. Various additional terms (e.g. inverse of sample size $\\frac{1}{|B|}$, $\\frac{1}{|B|^2}$, learning rate $\\eta$,  firt momentum rate dependent term $1 - \\beta_1$, or 2nd momentum rate dependent term $1 -\\beta_2$) are multiplied into the gradient of an individual sample for the subsequent aggregation steps (e.g. summation) in a single GPU or across GPUs. \n",
    "2. The gradient of invidual example $\\nabla_{w_t} l(w_t, x_i)$ might need to be transformed locally for individual sample, e.g. square operator: $\\nabla_{w_t} l(w_t, x_i) \\odot \\nabla_{w_t} l(w_t, x_i)$.\n",
    "\n",
    "**Please correct me if the above observation is incorrect or incomplete.**\n",
    "\n",
    "Therefore, for various SGD algorithms, the key APIs are to \n",
    "1. Compute gradient for individual sample loss $\\nabla l(w_t, x_i)$\n",
    "2. Retrieve optimiation context for an indivdual sample. The optimization context might include the size of the minibatch which this example belongs to, learning rate, optimization algorithm specific rate such as $\\beta_1$ and $\\beta_2$\n",
    "3. Subsequent one or more aggregation steps, e.g. summation in SGD. \n",
    "\n",
    "\n",
    "## The learning parameter should be functional\n",
    "Each parameter can either be \n",
    "* a simple primitive value, e.g. int, double, string\n",
    "* a functional which returns value based on the learning context --- compute the value on-the-fly based on other values in the context, or return a cached value.\n",
    "These parameters are then embeded into the LearningContext.\n",
    "\n",
    "For example, \n",
    "* In Python:\n",
    "```python\n",
    "    options = C.Learners.Options()\n",
    "    options[ParameterName] = value \n",
    "    ...\n",
    "    options['MomentumRate'] = lambda learning_context: learning_context['LearningRate'] **  learning_context['NumIteration'] \n",
    "```\n",
    "* In C++:\n",
    "```c++\n",
    "    options = new CNTK::LearningOptions();\n",
    "    options.Set(ParameterName, value);\n",
    "    ...\n",
    "    options.Set(\"MomentumRate\", [](LearningContext& learning_context){\n",
    "        return pow(learning_context.Get<double>(\"LearningRate\"),  learning_context.Get<double>(\"NumIteration\"));\n",
    "    });    \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# C++ LearnerContext and LearningOptions\n",
    "The LearnerContext is encapsulated in the C++ class LearningContext. Its template member functions Get() and Set() support \n",
    "\n",
    "* Primitive types, e.g. int, double, \n",
    "* Object, \n",
    "* Functional object: ContextFunction<ReturnValueType>::function. A specific functional object is CNTK function which can handle batch and sequence axes for tensor operations. \n",
    "\n",
    "The Get() function returns the built-in context values: e.g. number of samples, number of sweeps and etc. These values are either computed on the fly or the training process explicitly call the Set() function to set it into the context for later reference. The context values are set in a lazy manner: If the value is not requested for the iteration, it won't be computed. \n",
    "\n",
    "\n",
    "```c++\n",
    "typedef std:wstring KeyType;\n",
    "\n",
    "/**\n",
    "A class encapsulate learner context. \n",
    "**/\n",
    "class LearningContext{\n",
    "private: \n",
    "   ///Each supporting value type will has its own dictionary. This should be thread-safe map which will be implemented through mutex or through libraries which provide ConcurrentMap.\n",
    "   template <typename T> unordered_map<KeyType, T>& GetDict();\n",
    "public:\n",
    "    typedef std:wstring KeyType;\n",
    "    ///If T is non-functional return the values in the context; if T is functional, execute the functions. \n",
    "    template <typename T> const T& Get(const KeyType& key) const;\n",
    "    template <typename T> const T& Set(const KeyType& key, const T& value) const;\n",
    "};\n",
    "\n",
    "/**\n",
    "A template class which help to define functional object types.\n",
    "*/\n",
    "template <class ReturnValueType> ContextFunction{\n",
    "public:\n",
    "    typedef std:function<ReturnValueType(LearnerContext&)> function;\n",
    "};\n",
    "\n",
    "///LearningOptions have the same interface as LearningContext\n",
    "class LearningOptions{\n",
    "private: \n",
    "   ///Each supporting value type will has its own dictionary. \n",
    "   template <typename T> unordered_map<KeyType, T>& GetDict();\n",
    "public:\n",
    "    ///If T is non-functional return the values in the context; if T is functional, execute the functions. \n",
    "    template <typename T> const T& Get(const KeyType& key) const;\n",
    "    template <typename T> const T& Set(const KeyType& key, const T& value) const;\n",
    "};\n",
    "```\n",
    "\n",
    "### Additional data objects:\n",
    "* RateOnMinibatch(double value, int as_for_num_of_samples)\n",
    "* (to be completed)\n",
    "\n",
    "### Schedules\n",
    "* Schedules will be a function of the type ContextFunction<double>::function which retrieves the LearnerContext::Get(SWEEP_NUM) or LearnerContext::Get(ITERATION_NUM) and bases on the retreived value return the learning rates, momentum rates, minibatch size and other parameters.\n",
    "\n",
    "### Metrics depending functions\n",
    "* We will implement a list of basic built-in metrics in the context: loss, errrors and so on. This metrics will be computed in a lazy manner --- only when they are called, they will be computed for the corresponding iteration; and if they are requested, they will be computed only once per iteration.\n",
    "* Customized metrics based on CNTK function defined through functional type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usages of the LearningContext\n",
    "There should be a learning context per each iteration and per each worker. This context has various built-in values, e.g. number of sweeps, number of minibatches, and so on. These built-in values can have local values and global values which are referenced by different keys. \n",
    "\n",
    "To the make the idea concrete, examples are in Python are provided below (C++ counterparts are similar).\n",
    "\n",
    "* For minibatch SGD:\n",
    "```python\n",
    "sample_coefficient =   learning_context[LEARNING_RATE] *  (1 / learning_context[MINIBATCH_SIZE])\n",
    "w = w - sample_coefficient * gradient(sample)\n",
    "```\n",
    "\n",
    "* For ADAM:\n",
    "```python\n",
    "#The following will need to be converted into matrix notation\n",
    "batch_size =  learning_context[MINIBATCH_SIZE]\n",
    "alpha =  learning_context[ALPHA]\n",
    "beta1 =  learning_context[BETA1]\n",
    "beta2 = learning_context[BETA2]\n",
    "sample_coefficient1 =  (1 - beta1)  *  (1 / batch_size)\n",
    "sample_coefficient2 =  (1 - beta2) *  (1 / (batch_size * batch_size))\n",
    "sample_gradient = gradient(sample)\n",
    "mm = beta1 * m + sample_coefficient1 * sample_gradient #update the momentum \n",
    "vv = beta2 * v + sample_coefficient2 * sample_gradient #update the 2nd momentum\n",
    "#...after all samples are collected into mm and vv\n",
    "mm = mm / ( 1 - beta1 ** t) #this can be reformulated into a more distributed manner\n",
    "vv = vv / (1 - beta2 ** t) #this can be reformulated into a more distributed manner\n",
    "vv = sqrt(vv)\n",
    "w = w - alpha * mm / (vv + epsilon)\n",
    "#...synchronization\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python learner interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SWIG tricks\n",
    "* The C++ LearnerContext class will be ported into Python\n",
    "* Python lambda functions will be translated into C++ function objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python learner APIs with Options\n",
    "* Each learner should be defined with the parameter as they are in the literature\n",
    "    For example, \n",
    "    ```python\n",
    "    adam_learner = C.learners.adam(alpha = 0.1, beta1 = 0.2, beta2 = 0.3)\n",
    "    ```\n",
    "* Each learner definition return partial definition of the learners through a lambda of type: Callable[[LearningOptions], C.learners.Learner]. It is the trainer or trainning session which finalizes the learner with additional option setting. A possible implementation is: \n",
    "    ```python\n",
    "    def adam(alpha, beta1, beta2):\n",
    "        def ret_adam(options: LearningOptions) ->  Learner:\n",
    "            options['alpha'] = alpha\n",
    "            options['beta1'] = beta1\n",
    "            options['beta2'] = beta2\n",
    "            return C.learners.sgd_impl(options)\n",
    "        return ret_adam\n",
    "    ```\n",
    "* The learner can also be specified without any options so as to depend on the trainer or trainning sesssion specification. For example, \n",
    "    ```python\n",
    "learner = C.learners.sgd  #  return type: Callable[[LearningOptions], Learner]\n",
    "learner = C.learners.adam  #  return type: Callable[[LearningOptions], Learner]\n",
    "learner = C.learners.adadelta  #  return type: Callable[[LearningOptions], Learner]\n",
    "    ```\n",
    "    \n",
    "* Backward compatibility is achieved through setting property fields in options. For example,\n",
    "    ```python\n",
    "def sgd(parameters, lr, l1_regularization_weight=0, l2_regularization_weight=0, gaussian_noise_injection_std_dev=0, gradient_clipping_threshold_per_sample=np.inf, gradient_clipping_with_truncation=True):\n",
    "    def ret_sgd(options: LearningOptions) ->  Learner:\n",
    "        options['LearningRate'] = lr\n",
    "        options['l1_regularization_weight'] = l1_regularization_weight\n",
    "        ...\n",
    "        return C.learners.sgd_impl(options)\n",
    "    return ret_sgd\n",
    "    ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Trainer API\n",
    "```python\n",
    "def trainer(model, \n",
    "        loss, \n",
    "        learner, \n",
    "        options: C.learners.Options,\n",
    "        # Based on the schedule, do something on the learning context: e.g. logging\n",
    "        progress_callback: Callable[[Schedule, LearningContext]] \n",
    "        ) -> Trainer\n",
    "```\n",
    "\n",
    "## Backward compatibility is achieved through inspecting the python function parameter list and set the options correspondingly\n",
    "For example, we also allow the following usage in Python but it won't be encouraged:\n",
    "```python\n",
    "trainer = C.learners.trainer(\n",
    "       model = model,\n",
    "       loss, # = cross_entropy(model, label)\n",
    "       learner = learner, #C.learners.sgd\n",
    "       reader = reader, #C.io.readers\n",
    "       progress_logger, # \n",
    "       learning_rate, #   \n",
    "       momentum_rate, #  e\n",
    "       mb_size, # = lambda num_of_sample_processed: return adjusted_mb_size,\n",
    "       # different learners and optimizers can register additional parmaters\n",
    "       beta1 # for adam\n",
    "       beta2 # for adam, \n",
    "       ....\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regarding refactoring UnitType: per sample and per minibatch\n",
    "* A helper class\n",
    "```python\n",
    "RateOnMinibatch(value, as_for_number_of_samples, as_for_number_of_sequences)\n",
    "```\n",
    "    * value: The value of this rate.\n",
    "    * as_for_number_of_samples: How many samples are this rate intended to apply on as a group in theory.\n",
    "    * as_for_number_of_sequences: How many sequences are this rate intended to apply on as a group in theory.\n",
    "    \n",
    "Note that    \n",
    "* Learning rate, momentum rate and second momentum rate will all use this class\n",
    "* End user specifies the numbers as they are in the literature. The specific learners convert them into per sample coefficient for computational efficiency consideration.\n",
    "    \n",
    "Examples:    \n",
    "```python\n",
    "learner = C.learners.sgd(learning_rate = RateOnMinibatch(0.002, as_for_number_of_samples = 1))\n",
    "learner = C.learners.sgd(learning_rate = RateOnMinibatch(0.2 ,as_for_number_of_samples = 100))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regarding schedules\n",
    "As learning options are functional, the schedules can be specified in the following ways:\n",
    "* In functional manner\n",
    "```python\n",
    "learner = C.learners.sgd(\n",
    "    learning_rate = lambda learning_context: RateOnMinibatch(0.2 , 100) if learning_context['NumInteration'] < 100 else RateOnMinibatch(0.02, 100)\n",
    "    )\n",
    "```\n",
    "* In array manner for backward compatibility\n",
    "```python\n",
    "learner = C.learners.sgd(\n",
    "    learning_rate = [ (999, RateOnMinibatch(0.2 , 100)), (888, RateOnMinibatch(0.4 , 100))]\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional helper functions\n",
    "We will provide additional helper functions to help users write simple dynamic labmda functions, such as:\n",
    "\n",
    "* Parameter on minibatch size\n",
    "```python\n",
    "def parameter_on_minibatch_size(lamda_function):\n",
    "  '''\n",
    "  args\n",
    "      lambda_function: a function of form: minibatch_size -> Value\n",
    "  return a lamba function of the type Callabel[[LearningContext], Value]\n",
    "  '''\n",
    "  return lambda sample: mb_size = LearingContext['MB_SIZE']; lambda_function(mb_size)\n",
    "```\n",
    "* Parameter on number of iterations\n",
    "```python\n",
    "def parameter_on_num_iterations(lamda_function):\n",
    "  '''\n",
    "  args\n",
    "      lambda_function: a function of form: num_iterations -> Value\n",
    "  return a lamba function of the type Callabel[[LearningContext], Value]\n",
    "  '''\n",
    "  return lambda sample: num_iter = LearingContext['NumIterations']; lambda_function(num_iter)\n",
    "```\n",
    "  \n",
    "* Parameter on validation metrics\n",
    "```python\n",
    "def parameter_on_validation_metrics(dynamic_minibatch_size_lamda_function):\n",
    "  '''\n",
    "  args\n",
    "      lambda_function: a function of form: metrics -> Value\n",
    "  return a lamba function of the type Callabel[[LearningContext], Value]\n",
    "  '''\n",
    "  #for example, dynamic minibatch size\n",
    "  return lambda sample: loss = LearingContext['Loss']; dynamic_minibatch_size_lamda_function(loss)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Related modules\n",
    "* Readers: Reader should also be able to take functional minibatch size so as to feed the right size of minibath data  to the trainer/learner; the current next_minibatch API should work. We might want to configurate the reader in the same way as the learners'\n",
    "* Checkpoints: Checkpoints need to store models, LearningContext and LearnerOptions correctly; and restore early version models with new options correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
