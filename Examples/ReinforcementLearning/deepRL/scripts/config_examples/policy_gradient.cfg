# See agent/shared/policy_gradient_parameters.py for detailed explanation of
# each parameter.

[General]
Gamma = 0.99
# PreProcessing = AtariPreprocessing
# PreProcessingArgs = (4,)

[PolicyGradient]
SharedRepresentation = False
PolicyRepresentation = nn
InitialPolicy =
# ValueFunctionRepresentation is ignored when SharedRepresentation is true
ValueFunctionRepresentation = nn
UpdateFrequency = 32
RelativeStepSize = 0.5
RegularizationWeight = 0.001

[NetworkModel]
# Use (a list of integers) when PolicyRepresentation is nn
PolicyNetworkHiddenLayerNodes = [20]

# Use (a list of integers) when ValueFunctionRepresentation is nn, ignored when
# SharedRepresentation is true
ValueNetworkHiddenLayerNodes = [20]

[Optimization]
Momentum = 0.95
InitialEta = 0.01
EtaDecayStepCount = 10000
EtaMinimum = 0.01
